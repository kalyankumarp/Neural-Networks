{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "n= 300\n",
    "x = [np.random.uniform(low =0, high = 1) for i in range(n)]\n",
    "# Vector Fields\n",
    "v = [np.random.uniform(low =-0.1, high = 0.1) for i in range(n)]\n",
    "#v\n",
    "mean = np.mean(x)\n",
    "std  = np.std(x)\n",
    "x_stand = []\n",
    "for i in range(len(x)):\n",
    "    x_stand.append([1,(x[i]-mean)/std])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = []\n",
    "for i in range(0,n):\n",
    "    d.append(sin(20*x[i]) + 3*x[i] + v[i])\n",
    "d = np.asarray(d)\n",
    "# d\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "x = np.asarray(x)\n",
    "#print(x)\n",
    "plt.scatter(x,d, s  = 7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.31064437,  1.41080004,  1.55129898,  1.10644356,  0.5563052 ,\n",
       "        1.11358352,  0.61272377,  0.04394529,  1.81312407,  1.78931063,\n",
       "        0.82198841, -0.17430109,  1.63562625,  1.18575938,  0.60970696,\n",
       "        0.78137092,  1.76107968,  2.87683276,  2.00282836,  2.00247014,\n",
       "        0.55903863,  0.1450023 ,  0.28362261,  1.06527937,  1.2808711 ,\n",
       "        1.86123729,  0.61278361, -0.25208851,  1.2504448 ,  1.14976407,\n",
       "        2.15690572,  1.20711144,  0.95566525,  1.12843369,  2.14234554,\n",
       "        2.48523518,  2.76264252,  0.88728044,  0.58014614,  0.11682797,\n",
       "        2.91105439,  2.15294795,  0.59340109,  0.0409165 ,  1.20389617,\n",
       "        0.82405061,  1.82525504,  0.46051939,  2.48575015,  1.26027422,\n",
       "        2.8676778 ,  1.21718107,  2.03754062,  1.81416779,  2.61803776,\n",
       "        1.45547126,  0.18111766, -0.17757445,  1.2865396 ,  2.86872455,\n",
       "        0.70946704,  2.04279841,  0.79033585,  1.65961603,  4.0001643 ,\n",
       "        2.94316961,  0.64934433,  2.07850084,  0.39828717,  1.97109264,\n",
       "        1.28670069,  1.24916376, -0.20314338,  2.12032631,  1.21439797,\n",
       "        1.78774094,  1.5800541 ,  3.67359536,  1.76571749,  1.94748162,\n",
       "        0.88833236,  1.61120819,  0.54653066,  1.36909866,  3.15467302,\n",
       "        1.32044937,  0.59063926,  1.66839836,  0.86610315,  0.92656964,\n",
       "        0.72209414,  1.55702892, -0.2438986 ,  2.65334825,  1.33260504,\n",
       "        2.55692028,  1.30340974,  0.16115107,  1.2055567 ,  2.97644495,\n",
       "        1.09097634,  1.38239274,  1.20833757,  2.85568142, -0.13725842,\n",
       "        0.99090535,  1.75603287,  2.70868612,  0.81769776,  1.0647946 ,\n",
       "        2.24647712,  1.60348641,  2.65301121, -0.09498919, -0.13063467,\n",
       "        2.46233095,  2.03150019,  0.09613221, -0.3821201 ,  0.31078419,\n",
       "        3.14481919,  2.20687518,  1.62352617,  1.64034228,  0.65489477,\n",
       "        0.11854454, -0.12299276,  1.02200671, -0.05968036, -0.04737908,\n",
       "        1.89033981,  1.28516887,  2.50356912,  2.19559843,  1.01418179,\n",
       "        3.05253911,  1.06232129,  3.17656687,  1.2883119 ,  2.2320407 ,\n",
       "        2.92499643,  0.80173553,  0.97737861, -0.08003794,  0.61684145,\n",
       "        0.31293805,  1.02344745,  2.78894863, -0.23242571, -0.30675958,\n",
       "        2.62213513,  1.59524976,  1.63236761,  2.69315003,  0.77082759,\n",
       "        1.84433758,  2.66191317,  0.64875856,  2.45447783,  2.93956052,\n",
       "        1.86422589,  3.65516474,  2.33559557,  0.87370542,  0.72262759,\n",
       "        1.21857865,  2.05555604,  1.93816009,  2.25696256,  1.57523617,\n",
       "        3.06679832,  1.06466873,  1.36414095, -0.24209293,  3.03775461,\n",
       "        0.16417066,  0.87448919,  3.07982011,  1.92946735,  2.01459154,\n",
       "        1.55470579,  2.08130737,  2.61854806,  2.20809272,  1.51102134,\n",
       "        2.61984801,  0.69261449,  3.76785263,  1.17390776,  2.25991634,\n",
       "        1.78719446,  2.59586933,  0.76519953,  2.96348938,  0.84048997,\n",
       "        2.90274177,  0.74813159,  0.98931432,  2.17443228,  3.01505227,\n",
       "        1.29964439,  3.59206106,  3.32498838,  1.94288973,  3.08876862,\n",
       "        2.51202868,  0.16264379,  2.14376742,  2.68351248,  3.66978874,\n",
       "        0.23067029, -0.32474129,  0.0180163 ,  1.84516022,  3.97175088,\n",
       "        2.51629645,  2.79521033,  2.07259974,  1.60601711,  2.18526254,\n",
       "        1.94428377,  0.73129991,  2.92122316,  1.24492278,  2.56919729,\n",
       "        2.2700044 ,  3.20872465,  2.80186246,  0.18816888,  3.52166573,\n",
       "        1.68831544,  1.86905022,  2.54015914,  2.47154791,  3.67252694,\n",
       "        2.03797343,  0.87010132,  0.02293261,  1.3235477 ,  2.56529528,\n",
       "        1.111895  ,  2.10925911,  2.28319432,  3.12038065,  1.59005919,\n",
       "        0.60419135,  2.14639168,  1.01234464,  1.19117498,  3.68387848,\n",
       "       -0.3966003 ,  1.07524089,  1.6608553 ,  0.10475194,  0.43078483,\n",
       "       -0.21895456,  1.76558044,  2.89668262,  2.95374882,  1.55642912,\n",
       "        1.1860039 ,  1.30324494,  0.9803538 ,  1.69313627,  0.83223344,\n",
       "        4.00212069,  3.63090651,  1.38861141, -0.23985462,  3.17119038,\n",
       "       -0.16971472,  1.96588616,  1.56698   ,  2.95340865,  2.47429363,\n",
       "        0.26968696,  2.68111791,  1.22444884,  1.21737741,  0.89082088,\n",
       "       -0.34632526,  2.85699617,  1.7391363 ,  1.1614867 ,  2.54691982,\n",
       "        0.94990083,  2.86366424,  1.58095367, -0.20926605,  3.66374674,\n",
       "        2.11645472,  1.58336463, -0.13374949,  2.24355815,  0.75037176,\n",
       "        2.72437822,  2.10421914,  3.80445188, -0.11928696,  0.41528008])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# #np.random.seed(100)\n",
    "\n",
    "# # hyperbolic Activation Function\n",
    "# def af(t):\n",
    "#     return tanh(t)\n",
    "\n",
    "# # Derivative of tanh(v)\n",
    "# def af_derivative(x):\n",
    "#     return 1-(tanh(x)**2)\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i]             \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(af(l))\n",
    "#             p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         #print(w[nLayers][\"weights\"][0])\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         c += (d[i] - y)**2            \n",
    "#     return c/n\n",
    "\n",
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "    \n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000, ep = 0):\n",
    "#         self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.temp_eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         self.ep = ep\n",
    "#         #self.train()\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "# #         newdata = []\n",
    "# #         for i in range(len(x)):\n",
    "# #             newdata.append(np.append(x[i],1))     \n",
    "    \n",
    "#     weights = [{\"weights\":np.random.rand(numNodes, len(x[0]))}] \n",
    "#     for i in range(self.nLayers-1):\n",
    "#         weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)})             \n",
    "#     if self.nLayers >= 0:            \n",
    "#         weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)})\n",
    "#     temp_weights = weights\n",
    "    \n",
    "          \n",
    "        \n",
    "#     def train(self):\n",
    "#         print(weights)\n",
    "#         temp_weights = weights\n",
    "#         temp_eta = self.temp_eta\n",
    "#         temp2 = mse(self.data, self.labels, weights, self.nLayers, self.nNodes)\n",
    "#         print(temp2)\n",
    "#         e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "#         cos = 100000000\n",
    "#         while cos >= self.ep and e <= self.maxIt:\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 self.backprop(self.labels[i], self.data[i]) \n",
    "#                 for m in range(len(weights)):\n",
    "#                     for j in range(len(weights[m]['weights'])):\n",
    "#                         for k in range(len(weights[m]['weights'][j])):\n",
    "#                             weights[m]['weights'][j][k] -= self.eta * weights[m]['g'][j][k]\n",
    "\n",
    "#             cos = mse(self.data, self.labels, weights, self.nLayers,self.nNodes)\n",
    "# #             epoch.append(e)\n",
    "# #             obj.append(cos)\n",
    "# #             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 cos = 100000000\n",
    "#                 weights = temp_weights\n",
    "#                 print(temp_weights)\n",
    "                \n",
    "#                 if self.eta <= 0.00001:                    \n",
    "#                     self.eta = temp_eta  \n",
    "# #                     obj =[]\n",
    "# #                     epoch = []\n",
    "# #                     e = 0\n",
    "# #                     cos = 100000000\n",
    "#                     weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}]\n",
    "#                     for i in range(self.nLayers-1):\n",
    "#                         weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)})\n",
    "#                     if self.nLayers > 0:\n",
    "#                         weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)})                    \n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "#         return weights, obj, epoch   \n",
    "       \n",
    "\n",
    "#     def feedforward(self,x=[]):\n",
    "#         prev = x\n",
    "#         r =[]      \n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.matmul(weights[j][\"weights\"][m], prev))           \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         p = np.matmul(weights[self.nLayers][\"weights\"][0], l)\n",
    "#         s.append(p)\n",
    "#         t.append(s)              \n",
    "#         return t,r, p        \n",
    "\n",
    "#     def backprop(self, d, data):\n",
    "#         der = []\n",
    "#         #t,r= self.feedforward(data)\n",
    "# #         print('\\n')\n",
    "# #         print(\"t = \" + str(t))\n",
    "# #         print('\\n')\n",
    "# #         print('r = ' + str(r))  \n",
    "#         t,r,q = self.feedforward(data)\n",
    "        \n",
    "#         for i in range(self.nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(self.nNodes):\n",
    "#                 a.append(af_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = []\n",
    "#         s =[]\n",
    "#         s.append(af_derivative(t[nLayers][0]))\n",
    "#         diff.append(d - q)\n",
    "#         der.append(s)\n",
    "    \n",
    "#         for i in reversed(range(len(weights))):\n",
    "#             layer = weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "                    \n",
    "#                     for k in range(len(weights[i + 1]['weights'])):\n",
    "#                         error += (weights[i + 1]['weights'][k][j] * weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff[0])\n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "\n",
    "# # Finding the corresponding gradient vector\n",
    "                \n",
    "#         for j in range(len(weights)):\n",
    "#             layer = weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(weights[j]['weights'][k])):\n",
    "#                     s.append(((-(r[j][m])*weights[j]['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "\n",
    "# hyperbolic Activation Function\n",
    "def af(t):\n",
    "    return tanh(t)\n",
    "\n",
    "# Derivative of tanh(v)\n",
    "def af_derivative(x):\n",
    "    return 1-(tanh(x)**2)\n",
    "\n",
    "def mse(x, d, w, nLayers, nNodes):\n",
    "    c = 0\n",
    "    n = len(x)\n",
    "    for i in range(0,n):\n",
    "        prev = x[i]             \n",
    "        for j in range(nLayers):\n",
    "            u =[]\n",
    "            p =[]\n",
    "            for k in range(nNodes):\n",
    "                t = np.dot(w[j]['weights'][k], prev)\n",
    "                u.append(t)\n",
    "            for l in u:\n",
    "                p.append(af(l))\n",
    "            p.append(1)\n",
    "            prev = np.asarray(p)\n",
    "        #print(w[nLayers][\"weights\"][0])\n",
    "        y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "        c += (d[i] - y)**2            \n",
    "    return c/n\n",
    "\n",
    "#np.random.seed(100)\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000, ep = 0):\n",
    "        self.labels = y\n",
    "        self.nLayers = numLayers\n",
    "        self.nNodes = numNodes\n",
    "        self.numOutputs = numOutputs\n",
    "        self.eta = eta\n",
    "        self.temp_eta = eta\n",
    "        self.maxIt = maxIter\n",
    "        self.ep = ep\n",
    "        #self.train()\n",
    "        #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         newdata = []\n",
    "#         for i in range(len(x)):\n",
    "#             newdata.append(np.append(x[i],1))     \n",
    "        self.data = x\n",
    "        self.weights = [{\"weights\":np.random.uniform(low =-2, high = 2, size = (self.nNodes, len(self.data[0])))}] \n",
    "        for i in range(self.nLayers):\n",
    "            self.weights.append({\"weights\":np.random.uniform(low =-2, high = 2, size = (self.nNodes,self.nNodes+1))})             \n",
    "        if self.nLayers >= 0:            \n",
    "            self.weights.append({\"weights\":np.random.uniform(low =-2, high = 2, size = (self.numOutputs,self.nNodes+1))})\n",
    "        self.temp_weights = self.weights\n",
    "          \n",
    "        \n",
    "    def train(self):\n",
    "        print(self.weights)\n",
    "        temp_weights = self.weights\n",
    "        temp_eta = self.temp_eta\n",
    "        temp2 = mse(self.data, self.labels, self.weights, self.nLayers+1, self.nNodes)\n",
    "        print(temp2)\n",
    "        e = 0\n",
    "        obj =[]\n",
    "        epoch = []\n",
    "        cos = 100000000\n",
    "        while cos >= self.ep and e < self.maxIt:\n",
    "            prev = cos\n",
    "            for i in range(len(self.data)):\n",
    "                self.backprop(self.labels[i], self.data[i]) \n",
    "                for m in range(len(self.weights)):\n",
    "                    for j in range(len(self.weights[m]['weights'])):\n",
    "                        for k in range(len(self.weights[m]['weights'][j])):\n",
    "                            self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "\n",
    "            cos = mse(self.data, self.labels, self.weights, self.nLayers+1,self.nNodes)\n",
    "#             epoch.append(e)\n",
    "#             obj.append(cos)\n",
    "#             e += 1\n",
    "\n",
    "            if cos >= prev:\n",
    "                self.eta = 0.9*self.eta\n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 obj.append(cos)\n",
    "#                 epoch.append(e)\n",
    "#                 cos = 100000000\n",
    "#                 self.weights = temp_weights\n",
    "#                 print(temp_weights)\n",
    "                \n",
    "                if self.eta <= 0.00001:                    \n",
    "                    self.eta = temp_eta  \n",
    "#                     obj =[]\n",
    "#                     epoch = []\n",
    "#                     e = 0\n",
    "#                     cos = 100000000\n",
    "                    self.weights = [{\"weights\":np.random.uniform(low =-2, high = 2, size = (self.nNodes, len(self.data[0])))}] \n",
    "                    for i in range(self.nLayers):\n",
    "                        self.weights.append({\"weights\":np.random.uniform(low =-2, high = 2, size = (self.nNodes,self.nNodes+1))})             \n",
    "                    if self.nLayers >= 0:            \n",
    "                        self.weights.append({\"weights\":np.random.uniform(low =-2, high = 2, size = (self.numOutputs,self.nNodes+1))})\n",
    "                          \n",
    "            elif cos < prev:\n",
    "                epoch.append(e)\n",
    "                obj.append(cos)\n",
    "                e += 1\n",
    "        return self.weights, obj, epoch   \n",
    "       \n",
    "\n",
    "    def feedforward(self,x=[]):\n",
    "        prev = x\n",
    "        r =[]      \n",
    "        r.append(prev)\n",
    "        t =[]\n",
    "        for j in range(self.nLayers+1):\n",
    "            l = []\n",
    "            s = []\n",
    "            for m in range(self.nNodes):\n",
    "                #print(self.weights[j][\"weights\"][m])\n",
    "                s.append(np.matmul(self.weights[j][\"weights\"][m], prev))           \n",
    "            for k in s:\n",
    "                l.append(af(k))\n",
    "            l.append(1)\n",
    "            prev = np.asarray(l)\n",
    "            t.append(s)\n",
    "            r.append(l)\n",
    "            \n",
    "        s =[]\n",
    "        p = np.matmul(self.weights[self.nLayers+1][\"weights\"][0], l)\n",
    "        s.append(p)\n",
    "        t.append(s)              \n",
    "        return t,r, p        \n",
    "\n",
    "    def backprop(self, d, data):\n",
    "        der = []\n",
    "        #t,r= self.feedforward(data)\n",
    "#         print('\\n')\n",
    "#         print(\"t = \" + str(t))\n",
    "#         print('\\n')\n",
    "#         print('r = ' + str(r))  \n",
    "        t,r,q = self.feedforward(data)\n",
    "        \n",
    "        for i in range(self.nLayers+1):\n",
    "            a =[]\n",
    "            for m in range(self.nNodes):\n",
    "                a.append(af_derivative(t[i][m]))\n",
    "            der.append(a)\n",
    "        \n",
    "        diff = []\n",
    "        s =[]\n",
    "        s.append(af_derivative(t[self.nLayers+1][0]))\n",
    "        diff.append(d - q)\n",
    "        der.append(s)\n",
    "    \n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            layer = self.weights[i]\n",
    "            errors = []\n",
    "            if i != len(self.weights)-1:\n",
    "                for j in range(len(layer['weights'])):\n",
    "                    error = 0\n",
    "                    \n",
    "                    for k in range(len(self.weights[i + 1]['weights'])):\n",
    "                        error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "                    errors.append(error)\n",
    "            else:\n",
    "                errors.append(diff[0])\n",
    "            layer['s'] = []\n",
    "            for j in range(len(layer['weights'])):\n",
    "                layer['s'].append(errors[j]*der[i][j])\n",
    "\n",
    "# Finding the corresponding gradient vector\n",
    "                \n",
    "        for j in range(len(self.weights)):\n",
    "            layer = self.weights[j]\n",
    "            layer['g'] = []\n",
    "            for k in range(len(self.weights[j]['weights'])):\n",
    "                s =[]\n",
    "                for m in range(len(self.weights[j]['weights'][k])):\n",
    "                    s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "                layer['g'].append(s)\n",
    "\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(105)\n",
    "class Neural_Network():\n",
    "    \n",
    "    def __init__(self, x=[[]], y=[], nHiddenLayers = 0, nHiddenNodes =0, numOutputs = 0, eta = 1, iter = 0, prec = 0):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        self.nInputNodes = x.shape[1]\n",
    "        self.nHiddenLayers = nHiddenLayers\n",
    "        self.nHiddenNodes = nHiddenNodes\n",
    "        self.numOutputs = numOutputs\n",
    "        self.eta = eta\n",
    "        self.maxIt = iter\n",
    "        self.prec = prec\n",
    "        \n",
    "        #weights\n",
    "        self.weights=[np.random.uniform(low = -1, high = 1, size = (self.nHiddenNodes, self.nInputNodes))]\n",
    "        for i in range(self.nHiddenLayers-1):\n",
    "            self.weights.append(np.random.uniform(low =-1, high = 1, size =(self.nHiddenNodes, self.nHiddenNodes))) \n",
    "        self.weights.append(np.random.uniform(low =-1, high = 1, size = (self.numOutputs, self.nHiddenNodes)))\n",
    "\n",
    "    # hyperbolic Activation Function\n",
    "    def af(self, t):\n",
    "        return np.tanh(t)\n",
    "\n",
    "    # Derivative of tanh(v)\n",
    "    def af_derivative(self, x):\n",
    "        return 1-(x**2)\n",
    "    \n",
    "    def misclassifications(self, x,y):\n",
    "#         print(x)\n",
    "#         print(y)\n",
    "        #print(f)\n",
    "        count = 0\n",
    "#         x = x.reshape(1,y.shape[1])\n",
    "        for i in range(y.shape[0]): \n",
    "            if np.any(x[i]-y[i]):\n",
    "                count += 1\n",
    "        return count\n",
    "    \n",
    "    def predict(self):\n",
    "#         print(x.shape)\n",
    "#         print(f)\n",
    "        prev = self.data.T\n",
    "        for i in range(len(self.weights)-1):         \n",
    "\n",
    "            temp = (np.matmul(self.weights[i], prev))\n",
    "            #print(temp)\n",
    "            temp2 = self.af(temp)\n",
    "            prev = temp2\n",
    "        temp_f = np.matmul(self.weights[self.nHiddenLayers], prev)\n",
    "        #print(temp_f)\n",
    "        temp4 = self.af(np.transpose(temp_f))\n",
    "#         print(temp4)\n",
    "#         print(f)       \n",
    "        return temp4\n",
    "#         return temp_f\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        self.r = []\n",
    "        self.r.append(x)\n",
    "#         print(x)\n",
    "#         print(x.shape)\n",
    "#         print(f)\n",
    "        prev = x.T\n",
    "        for i in range(len(self.weights)-1):\n",
    "\n",
    "            temp = np.matmul(self.weights[i], prev)\n",
    "\n",
    "            temp2 = self.af(temp)\n",
    "            self.r.append(temp2)\n",
    "            prev = temp2\n",
    "            #print(prev.shape)\n",
    "            \n",
    "#         print(self.weights[self.nHiddenLayers])\n",
    "#         print(prev)        \n",
    "        temp_f = np.matmul(self.weights[self.nHiddenLayers], prev)\n",
    "        temp4 = self.af(temp_f.T) \n",
    "#         print(temp4)\n",
    "#         print(f)\n",
    "        return temp4\n",
    "#         return temp_f\n",
    "\n",
    "    def backward(self, x, y):\n",
    "#         print(x)\n",
    "#         print(y)\n",
    "#         print(f)\n",
    "        \n",
    "        o = self.feedforward(x) \n",
    "\n",
    "\n",
    "        self.out_error = y - o\n",
    "        #print(self.out_error)\n",
    "#         print(f)\n",
    "        #o = o.reshape(self.numOutputs,1)\n",
    "\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            if i == 0 and i != len(self.weights)-1:\n",
    "                temp2 = self.weights[i+1].T.dot(temp) \n",
    "#                 print(temp2.shape)\n",
    "#                 print(self.sigmoidPrime(self.r[i+1]).shape)\n",
    "                temp3 = temp2*self.af_derivative(self.r[i+1])\n",
    "#                 print(temp3.shape)\n",
    "                temp4 = self.eta*(temp3.dot(x)*2/len(self.data))\n",
    "#                 print(self.weights[i])\n",
    "#                 print(temp4)\n",
    "\n",
    "                self.weights[i] += temp4\n",
    "#                 print(self.weights[i])\n",
    "#                 print(f)\n",
    "                temp = temp3\n",
    "                    \n",
    "            elif i > 0 and i<len(self.weights)-1:\n",
    "                temp2 = self.weights[i+1].T.dot(temp) \n",
    "#                 print(temp2.shape)\n",
    "#                 print(self.sigmoidPrime(self.r[i+1]).shape)\n",
    "                temp3 = temp2*self.af_derivative(self.r[i+1])\n",
    "#                 print(temp3.shape)\n",
    "                temp4 = self.eta*(temp3.dot(self.r[i])*2/len(self.data))\n",
    "#                 print(self.weights[i])\n",
    "#                 print(temp4)\n",
    "\n",
    "                self.weights[i] += temp4\n",
    "#                 print(self.weights[i])\n",
    "#                 print(f)\n",
    "#                 temp = temp3\n",
    "    \n",
    "#                 temp2 = temp.dot(self.weights[i+1])\n",
    "#                 temp3 = temp2*self.sigmoidPrime(self.r[i+1].T)\n",
    "#                 self.weights[i] += self.eta*(temp3.T.dot(self.r[i].T)*2/len(self.data))\n",
    "#                 temp = temp3\n",
    "                    \n",
    "            elif i == len(self.weights)-1:\n",
    "#                 print(o)\n",
    "#                 print(self.sigmoidPrime(o).reshape(1,10))\n",
    "                temp = self.out_error.reshape(self.numOutputs,1)\n",
    "                temp2 = temp*self.af_derivative(o)\n",
    "                temp2 = self.eta*(temp.dot(self.r[i].T)*2/len(self.data))\n",
    "#                 print(self.weights[i])\n",
    "#                 print(temp2)\n",
    "                self.weights[i] += temp2\n",
    "#                 print(self.weights[i])\n",
    "#                 print(f)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "    def train (self):\n",
    "        #print(self.eta)\n",
    "        print(self.weights)\n",
    "        e = 0\n",
    "        obj =[]\n",
    "        epoch = []\n",
    "        mis = []\n",
    "        epoch.append(e)\n",
    "        pred = self.predict()\n",
    "#         print(pred)\n",
    "#         print(f)\n",
    "        obj.append(((np.linalg.norm(self.labels - pred))**2)/len(self.data))\n",
    "        mis.append(self.misclassifications(self.labels, pred))\n",
    "        mse = 100000000000\n",
    "        while mse >= self.prec and e <= self.maxIt: \n",
    "            prev = mse\n",
    "            e += 1\n",
    "            for i in range(len(self.data)):\n",
    "                \n",
    "                self.backward(self.data[i].reshape(1,self.nInputNodes), self.labels[i])\n",
    "            pred = self.predict()\n",
    "\n",
    "            mse = ((np.linalg.norm(self.labels - pred))**2)/len(self.data)\n",
    "            if mse >= prev:\n",
    "                self.eta = 0.9*self.eta\n",
    "            \n",
    "            obj.append(mse)\n",
    "            epoch.append(e)\n",
    "            mis.append(self.misclassifications(self.labels, pred))\n",
    "            prev = mse\n",
    "        return self.weights, epoch, obj, mis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.83252015, -0.33298742],\n",
      "       [ 0.71871149, -0.78862633],\n",
      "       [ 0.07128009, -0.87262086],\n",
      "       [-0.40633084, -0.99550953],\n",
      "       [-0.09776818,  0.76723921],\n",
      "       [ 0.1541152 , -0.50224456],\n",
      "       [-0.31689389, -0.85960343],\n",
      "       [ 0.0769505 ,  0.05096746],\n",
      "       [ 0.63759327,  0.37266117],\n",
      "       [ 0.26193424, -0.25922173],\n",
      "       [ 0.07221705, -0.65367605],\n",
      "       [-0.66812484, -0.77906106],\n",
      "       [-0.34829424,  0.79482807],\n",
      "       [ 0.09687408, -0.51725936],\n",
      "       [-0.3439928 ,  0.17785681],\n",
      "       [ 0.59034121, -0.03765631],\n",
      "       [ 0.15237202,  0.18022797],\n",
      "       [ 0.5957956 ,  0.55624745],\n",
      "       [ 0.33329485,  0.02245098],\n",
      "       [ 0.07270957, -0.653556  ],\n",
      "       [ 0.35149003,  0.816316  ],\n",
      "       [ 0.07097401, -0.63155823],\n",
      "       [-0.81728084,  0.14211686],\n",
      "       [ 0.64930064, -0.6855588 ]]), array([[ 0.31735832, -0.81612776,  0.89698664, -0.80844927, -0.14118148,\n",
      "         0.25399952,  0.54082223, -0.053505  , -0.44064723, -0.50320397,\n",
      "        -0.80448746,  0.50911242,  0.05040494,  0.60198286, -0.38583196,\n",
      "         0.23829088,  0.99846128,  0.49604484,  0.07713893, -0.15340265,\n",
      "        -0.96080091,  0.63044786, -0.80800567, -0.80165405]])]\n"
     ]
    }
   ],
   "source": [
    "nHiddenLayers = 1\n",
    "nHiddenNodes =24\n",
    "numOutputs = 1\n",
    "eta = 10\n",
    "iter = 100\n",
    "prec = 1\n",
    "x_stand = np.asarray(x_stand)\n",
    "NN = Neural_Network(x_stand, d, nHiddenLayers, nHiddenNodes, numOutputs, eta, iter, prec)\n",
    "\n",
    "w, epoch, obj, mis = NN.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ -6.81533253,  -0.37782131],\n",
       "        [-31.26143989, -42.57435977],\n",
       "        [  6.81566058,   0.37781854],\n",
       "        [-31.24496991, -42.55087365],\n",
       "        [ 31.34553896,  42.69184043],\n",
       "        [  6.81321495,   0.37783922],\n",
       "        [-31.33607699, -42.67875208],\n",
       "        [ 33.71236529,  45.95447258],\n",
       "        [ 32.92930118,  44.87545936],\n",
       "        [-31.33857917, -42.68144767],\n",
       "        [-31.24088853, -42.54554141],\n",
       "        [-31.62019936, -43.07050088],\n",
       "        [ 31.34648924,  42.69315427],\n",
       "        [  6.81559399,   0.3778191 ],\n",
       "        [ -6.81617225,  -0.37781422],\n",
       "        [  6.81635065,   0.37781271],\n",
       "        [  6.81757989,   0.37780234],\n",
       "        [  6.81685675,   0.37780844],\n",
       "        [  6.81511533,   0.37782314],\n",
       "        [-31.3921003 , -42.75542889],\n",
       "        [  6.80822688,   0.37788147],\n",
       "        [  6.81519773,   0.37782245],\n",
       "        [ -6.81800435,  -0.37779877],\n",
       "        [-31.26303638, -42.57658466]]),\n",
       " array([[-539.07708959, -539.89822842,  539.25383503, -540.70310207,\n",
       "          538.41523141,  537.9383473 , -538.44257871,  536.80748722,\n",
       "          538.08705115, -539.27293755, -540.37297001, -538.88363814,\n",
       "          538.41317166,  539.21813635, -539.52969617,  539.62576208,\n",
       "          540.28915253,  539.89828802,  538.96046943, -539.17329933,\n",
       "          535.24185994,  539.00468184, -540.51834002, -539.87623702]])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperbolic Activation Function\n",
    "def af(t):\n",
    "    return np.tanh(t)\n",
    "\n",
    "# Derivative of tanh(v)\n",
    "def af_derivative(x):\n",
    "    return 1-(x**2)\n",
    "\n",
    "def predict(x,w, nHiddenLayers):\n",
    "    prev = x.T\n",
    "    for i in range(len(w)-1):\n",
    "        temp = (np.matmul(w[i], prev))\n",
    "        temp2 = af(temp)\n",
    "        prev = temp2\n",
    "    temp_f = np.matmul(w[nHiddenLayers], prev)\n",
    "    temp4 = af_derivative(np.transpose(temp_f))      \n",
    "    return temp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = predict(x_stand, w, 1)\n",
    "len(x_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.31064437,  1.41080004,  1.55129898,  1.10644356,  0.5563052 ,\n",
       "        1.11358352,  0.61272377,  0.04394529,  1.81312407,  1.78931063,\n",
       "        0.82198841, -0.17430109,  1.63562625,  1.18575938,  0.60970696,\n",
       "        0.78137092,  1.76107968,  2.87683276,  2.00282836,  2.00247014,\n",
       "        0.55903863,  0.1450023 ,  0.28362261,  1.06527937,  1.2808711 ,\n",
       "        1.86123729,  0.61278361, -0.25208851,  1.2504448 ,  1.14976407,\n",
       "        2.15690572,  1.20711144,  0.95566525,  1.12843369,  2.14234554,\n",
       "        2.48523518,  2.76264252,  0.88728044,  0.58014614,  0.11682797,\n",
       "        2.91105439,  2.15294795,  0.59340109,  0.0409165 ,  1.20389617,\n",
       "        0.82405061,  1.82525504,  0.46051939,  2.48575015,  1.26027422,\n",
       "        2.8676778 ,  1.21718107,  2.03754062,  1.81416779,  2.61803776,\n",
       "        1.45547126,  0.18111766, -0.17757445,  1.2865396 ,  2.86872455,\n",
       "        0.70946704,  2.04279841,  0.79033585,  1.65961603,  4.0001643 ,\n",
       "        2.94316961,  0.64934433,  2.07850084,  0.39828717,  1.97109264,\n",
       "        1.28670069,  1.24916376, -0.20314338,  2.12032631,  1.21439797,\n",
       "        1.78774094,  1.5800541 ,  3.67359536,  1.76571749,  1.94748162,\n",
       "        0.88833236,  1.61120819,  0.54653066,  1.36909866,  3.15467302,\n",
       "        1.32044937,  0.59063926,  1.66839836,  0.86610315,  0.92656964,\n",
       "        0.72209414,  1.55702892, -0.2438986 ,  2.65334825,  1.33260504,\n",
       "        2.55692028,  1.30340974,  0.16115107,  1.2055567 ,  2.97644495,\n",
       "        1.09097634,  1.38239274,  1.20833757,  2.85568142, -0.13725842,\n",
       "        0.99090535,  1.75603287,  2.70868612,  0.81769776,  1.0647946 ,\n",
       "        2.24647712,  1.60348641,  2.65301121, -0.09498919, -0.13063467,\n",
       "        2.46233095,  2.03150019,  0.09613221, -0.3821201 ,  0.31078419,\n",
       "        3.14481919,  2.20687518,  1.62352617,  1.64034228,  0.65489477,\n",
       "        0.11854454, -0.12299276,  1.02200671, -0.05968036, -0.04737908,\n",
       "        1.89033981,  1.28516887,  2.50356912,  2.19559843,  1.01418179,\n",
       "        3.05253911,  1.06232129,  3.17656687,  1.2883119 ,  2.2320407 ,\n",
       "        2.92499643,  0.80173553,  0.97737861, -0.08003794,  0.61684145,\n",
       "        0.31293805,  1.02344745,  2.78894863, -0.23242571, -0.30675958,\n",
       "        2.62213513,  1.59524976,  1.63236761,  2.69315003,  0.77082759,\n",
       "        1.84433758,  2.66191317,  0.64875856,  2.45447783,  2.93956052,\n",
       "        1.86422589,  3.65516474,  2.33559557,  0.87370542,  0.72262759,\n",
       "        1.21857865,  2.05555604,  1.93816009,  2.25696256,  1.57523617,\n",
       "        3.06679832,  1.06466873,  1.36414095, -0.24209293,  3.03775461,\n",
       "        0.16417066,  0.87448919,  3.07982011,  1.92946735,  2.01459154,\n",
       "        1.55470579,  2.08130737,  2.61854806,  2.20809272,  1.51102134,\n",
       "        2.61984801,  0.69261449,  3.76785263,  1.17390776,  2.25991634,\n",
       "        1.78719446,  2.59586933,  0.76519953,  2.96348938,  0.84048997,\n",
       "        2.90274177,  0.74813159,  0.98931432,  2.17443228,  3.01505227,\n",
       "        1.29964439,  3.59206106,  3.32498838,  1.94288973,  3.08876862,\n",
       "        2.51202868,  0.16264379,  2.14376742,  2.68351248,  3.66978874,\n",
       "        0.23067029, -0.32474129,  0.0180163 ,  1.84516022,  3.97175088,\n",
       "        2.51629645,  2.79521033,  2.07259974,  1.60601711,  2.18526254,\n",
       "        1.94428377,  0.73129991,  2.92122316,  1.24492278,  2.56919729,\n",
       "        2.2700044 ,  3.20872465,  2.80186246,  0.18816888,  3.52166573,\n",
       "        1.68831544,  1.86905022,  2.54015914,  2.47154791,  3.67252694,\n",
       "        2.03797343,  0.87010132,  0.02293261,  1.3235477 ,  2.56529528,\n",
       "        1.111895  ,  2.10925911,  2.28319432,  3.12038065,  1.59005919,\n",
       "        0.60419135,  2.14639168,  1.01234464,  1.19117498,  3.68387848,\n",
       "       -0.3966003 ,  1.07524089,  1.6608553 ,  0.10475194,  0.43078483,\n",
       "       -0.21895456,  1.76558044,  2.89668262,  2.95374882,  1.55642912,\n",
       "        1.1860039 ,  1.30324494,  0.9803538 ,  1.69313627,  0.83223344,\n",
       "        4.00212069,  3.63090651,  1.38861141, -0.23985462,  3.17119038,\n",
       "       -0.16971472,  1.96588616,  1.56698   ,  2.95340865,  2.47429363,\n",
       "        0.26968696,  2.68111791,  1.22444884,  1.21737741,  0.89082088,\n",
       "       -0.34632526,  2.85699617,  1.7391363 ,  1.1614867 ,  2.54691982,\n",
       "        0.94990083,  2.86366424,  1.58095367, -0.20926605,  3.66374674,\n",
       "        2.11645472,  1.58336463, -0.13374949,  2.24355815,  0.75037176,\n",
       "        2.72437822,  2.10421914,  3.80445188, -0.11928696,  0.41528008])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.74892603e-01, -1.65746321e+08, -1.67363263e+08,  9.73935786e-01,\n",
       "       -1.67363037e+08,  9.75801423e-01, -8.10831542e+02,  9.78791319e-01,\n",
       "       -1.67362937e+08, -1.67363273e+08, -1.67363078e+08,  9.68629794e-01,\n",
       "       -1.67230321e+08,  9.75502769e-01, -1.67363040e+08, -1.67363026e+08,\n",
       "       -1.67363245e+08, -1.67363167e+08, -1.67363125e+08, -1.67362800e+08,\n",
       "       -1.67363037e+08,  9.71239074e-01,  9.71510455e-01,  9.73732527e-01,\n",
       "       -1.50935290e+08, -1.67363279e+08, -1.67363050e+08,  9.68872401e-01,\n",
       "       -1.58651869e+08, -1.67363089e+08, -1.67363233e+08, -1.67362975e+08,\n",
       "       -1.67363077e+08, -1.67363090e+08, -1.67363234e+08, -1.67363224e+08,\n",
       "       -1.67363153e+08, -1.67363010e+08, -1.67363038e+08,  9.71236836e-01,\n",
       "       -1.67363160e+08, -1.67363283e+08, -1.67363037e+08,  9.70831519e-01,\n",
       "        9.74555919e-01, -1.67363073e+08, -1.67363247e+08,  9.71843363e-01,\n",
       "       -1.67363147e+08,  9.74530638e-01, -1.67363298e+08,  9.74362990e-01,\n",
       "       -1.67362907e+08, -1.67363122e+08, -1.67363219e+08, -1.67362965e+08,\n",
       "        9.00323666e-01,  9.68645449e-01,  9.74276964e-01, -1.67363210e+08,\n",
       "       -1.67363026e+08, -1.67363236e+08, -4.32932237e+05, -1.67363116e+08,\n",
       "       -1.67363314e+08, -1.67363207e+08, -1.67363040e+08, -1.67362898e+08,\n",
       "        9.77915955e-01, -1.67363243e+08,  9.74353342e-01,  9.74215638e-01,\n",
       "        9.69154073e-01, -1.67362813e+08,  9.73971298e-01, -1.67363119e+08,\n",
       "       -1.67234615e+08, -1.67363308e+08, -1.67362934e+08, -1.67362921e+08,\n",
       "       -3.21403855e+07, -1.67362955e+08, -1.67363051e+08, -1.67362965e+08,\n",
       "       -1.67363299e+08, -1.67362971e+08, -2.49393195e+02, -1.67363113e+08,\n",
       "       -1.67363015e+08, -1.83722907e+07, -1.67363049e+08, -1.67362954e+08,\n",
       "        9.69059870e-01, -1.67363293e+08, -1.67362970e+08, -1.67363149e+08,\n",
       "       -1.67362967e+08,  9.71054270e-01,  9.75947914e-01, -1.67363207e+08,\n",
       "       -1.67363096e+08, -1.67363103e+08, -1.67363100e+08, -1.67363212e+08,\n",
       "        9.70004313e-01,  9.73510839e-01, -1.67363276e+08, -1.67363294e+08,\n",
       "       -1.67363016e+08,  9.73767254e-01, -1.67362848e+08, -1.67348039e+08,\n",
       "       -1.67363220e+08,  9.68299223e-01,  9.68530571e-01, -1.67363291e+08,\n",
       "       -1.67362829e+08,  9.71100988e-01,  9.69255036e-01,  8.43382589e-01,\n",
       "       -1.67363189e+08, -1.67362872e+08, -1.67363267e+08, -1.67363115e+08,\n",
       "       -1.67363047e+08,  9.31624494e-01,  9.70265046e-01, -1.13610744e+08,\n",
       "        9.70807862e-01,  9.70703798e-01, -1.67363278e+08, -1.67363098e+08,\n",
       "       -1.67363224e+08, -1.67362852e+08, -1.67363000e+08, -1.67363300e+08,\n",
       "       -1.67363094e+08, -1.67363188e+08, -1.65232759e+08, -1.67363232e+08,\n",
       "       -1.67363168e+08, -1.67363077e+08,  9.73397283e-01,  9.70342098e-01,\n",
       "       -1.67363045e+08, -8.48625428e+00, -1.67362990e+08, -1.67363212e+08,\n",
       "        9.68969115e-01,  9.69053260e-01, -1.67363153e+08, -1.67362944e+08,\n",
       "       -1.67363265e+08, -1.67363151e+08, -1.67363007e+08, -1.67362364e+08,\n",
       "       -1.67363215e+08,  9.77613831e-01, -1.67363142e+08, -1.67363298e+08,\n",
       "       -1.67363242e+08, -1.67363307e+08, -1.67363228e+08, -1.67363005e+08,\n",
       "        9.72225770e-01, -1.67362979e+08, -1.67362890e+08, -1.67363243e+08,\n",
       "       -1.67363233e+08, -1.67363111e+08, -1.67363203e+08,  9.73762467e-01,\n",
       "       -1.67362972e+08,  9.69341858e-01, -1.67363176e+08,  8.57181724e-01,\n",
       "       -1.55508829e+06, -1.67363196e+08, -1.67362913e+08, -1.67362905e+08,\n",
       "       -1.67363269e+08, -1.67362835e+08, -1.67363147e+08, -1.67363232e+08,\n",
       "       -1.67313928e+08, -1.67363293e+08,  9.77509636e-01, -1.67363312e+08,\n",
       "       -1.67363100e+08, -1.67363233e+08, -1.67363278e+08, -1.67363291e+08,\n",
       "       -1.67363016e+08, -1.67363199e+08,  9.77133084e-01, -1.67363210e+08,\n",
       "       -1.67363053e+08,  9.73437163e-01, -1.67363133e+08, -1.67363167e+08,\n",
       "        9.74110850e-01, -1.67363309e+08, -1.67363303e+08, -1.67363242e+08,\n",
       "       -1.67363180e+08, -1.67363142e+08,  8.45715986e-01, -1.67363237e+08,\n",
       "       -1.67363220e+08, -1.67363308e+08,  9.71356858e-01,  9.69990566e-01,\n",
       "        9.67831068e-01, -1.67362930e+08, -1.67363313e+08, -1.67363146e+08,\n",
       "       -1.67363296e+08, -1.67362845e+08, -1.67363269e+08, -1.67362885e+08,\n",
       "       -1.67362909e+08, -1.67363063e+08, -1.67363161e+08, -1.67362976e+08,\n",
       "       -1.67363222e+08, -1.67363230e+08, -1.67363189e+08, -1.67363159e+08,\n",
       "        9.78558948e-01, -1.67363305e+08, -1.67363269e+08, -1.67362210e+08,\n",
       "       -1.67363220e+08, -1.67363227e+08, -1.67363309e+08, -1.67362822e+08,\n",
       "       -8.11838534e+05,  9.62065510e-01, -1.67363104e+08, -1.67363150e+08,\n",
       "       -1.16501417e+08, -1.67362835e+08, -1.67363135e+08, -1.67363200e+08,\n",
       "       -1.67363258e+08, -1.67363060e+08, -1.67362897e+08,  9.73356225e-01,\n",
       "        9.73892261e-01, -1.67363310e+08,  9.69476102e-01,  9.73259401e-01,\n",
       "       -1.67363117e+08,  9.71047958e-01, -4.12449173e+01,  9.69539516e-01,\n",
       "       -1.67355014e+08, -1.67363167e+08, -1.67363206e+08, -1.67363264e+08,\n",
       "       -1.67362986e+08, -1.67363097e+08,  9.73371994e-01, -1.67363275e+08,\n",
       "        9.72980247e-01, -1.67363314e+08, -1.67363307e+08, -1.64981024e+08,\n",
       "        9.70303200e-01, -1.67363299e+08,  9.70081472e-01, -1.67362795e+08,\n",
       "       -1.67363262e+08, -1.67363162e+08, -1.67363289e+08,  8.38320915e-01,\n",
       "       -1.67363220e+08, -1.67363101e+08,  9.74999338e-01,  9.72629231e-01,\n",
       "        9.68953448e-01, -1.67363207e+08, -1.67363253e+08,  9.73576495e-01,\n",
       "       -1.67363144e+08,  9.73185589e-01, -1.67363214e+08, -1.67363266e+08,\n",
       "        9.69679977e-01, -1.67363310e+08, -1.67363282e+08, -1.67363108e+08,\n",
       "        9.70503772e-01, -1.67362880e+08, -1.67363020e+08, -1.67363216e+08,\n",
       "       -1.67362839e+08, -1.67363310e+08,  9.67863913e-01, -1.56460511e+01])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1521675120699.3257"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = ((np.linalg.norm(d - y[:,0]))**2)/len(x_stand)\n",
    "cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(data, weights, nLayers, nNodes):\n",
    "    n =[]\n",
    "    for i in range(len(data)):\n",
    "        #print(i)\n",
    "        prev = data[i]\n",
    "\n",
    "        for j in range(nLayers):\n",
    "            l = []\n",
    "            s = []\n",
    "            for m in range(nNodes):\n",
    "                s.append(np.dot(weights[j][\"weights\"][m], prev))\n",
    "\n",
    "            for k in s:\n",
    "                l.append(tanh(k))\n",
    "            prev = np.asarray(l)\n",
    "\n",
    "        l.append(1)\n",
    "        p = np.dot(weights[nLayers][\"weights\"][0], l)  \n",
    "        #print(p)\n",
    "    \n",
    "        n.append(p)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot: the number of epochs vs the MSE in the backpropagation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIwAAAFNCAYAAABi2vQZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZxld1kn/s/TSzoJHegk3QSSdEjYBcZAjLKJ8mOX1RlRNhWBMeKIosKwOM6ADoyMoiIyM0zEsMm+KYOI7CAIwQQIJCxhp7OQdBNC0ll6q+/vj3MqfatSS3fouudW1fv9et2us91znnu+59zq+9T3+9xqrQUAAAAApq0ZOgAAAAAAJouEEQAAAAAzSBgBAAAAMIOEEQAAAAAzSBgBAAAAMIOEEQAAAAAzSBgBkKr6aFX9x5V6vEOlqr5dVQ8a6NjHVdXHq+rqqvrzIWKYbcjzcSAmPb7FVNUFVXX/Q7Sv+1fVRYdoX79WVZ84FPuatd9l+b7wozqU7XwQxzxk18M8+99ZVbddYP2yvjcBVgsJI4BVov8P+nX9f+Qvq6pXV9XGg9zHyVXVqmrdQTznhVX1dwcfMbOckWRHkpu31p41dDCTpqpeU1UvWsL9t/6+WTeybF1VXV5VbWTZXavq/VX1g6q6sqrOraqH9+vuX1VT/T04+rj3XMdsrd21tfbRHyHe29+U57J05rpOf5R2nlSttY2ttW8mS39vArB0JIwAVpdHtdY2JjktyU8m+cOB41mVDibhNuI2Sb7UWmuLbslSuTLJz43MPzzJD2Zt8/+SfCDJcUlumeR3klw1sv6S/sP06ONTSxn0anMT7y8OAeceYGWRMAJYhVprFyf5pyR3m72uqtZU1R9W1Xf63hOvq6pb9Ks/3v+8cqGeESP7eliSP0jyuH7780ZW36aqPtkPsXp/VW0eed69qupf+x4a5y00XKPvOfXsqvpCVf2wqt5SVYf36240dGa050X/l+//XVX/1Mf3yaq6VVW9rO8h8pWqusesQ/5kVX2pX//q6WP1+3tkVX2+j/tfq+rHZ8X53Kr6QpJr5vpgVVX3qap/61/Hv1XVfabjTPLkJM/p47zRUI6q2lBVL62q7/Y9YV5ZVUf06+5fVRdV1R9U1Y4+lieNPPcWfTtv79v9D6tqzcj6X6+qL/dt9aWqOm3k0Hef59xvrqr39Ofiiqr6l9F9juz7lVX10lnL/qGqfr+ffm5VXdwf+6tV9cA59nFGkieNnJ//t1h8i7XXPF6f5FdH5n81yetG9rc5ySlJ/qa1trt/fLK1dpOGb9XIsJ3qeuq9tW+nq6sbxnT6PM+bvk/P68/H40bWPau/ry+tqqeMLJ/3+pk/vPrr/rx+ZbRdquopI9fLN6vqN2Y98TH9eb+qqr5R3fvE7J3fum+3Z/fzH62qP6mqz/TH/IeqOqZfN93z8WlV9d0kH+6XP7o/T1f2z/+xWef2+TXHvVxVR/fX7vZ+3Xuq6sSR555S+4eHfrCq/leN9KKsqrdV1ff6OD9eVXftl895nc5q5w3Vvf9c0j9eVlUb+nXT9/GcbTjHOVywHWZte1pVfa7f9m39vfKikfW/XlVfr+5efndVHT+yrlXVb1XV15J8bWTZ7ed7zb353jumX+dzRl7nz1fVw6vqwj6GP5jvtQBwCLXWPDw8PDxWwSPJt5M8qJ/emuSCJP+9n/9okv/YTz81ydeT3DbJxiTvTPL6ft3JSVqSdSP7PSldz4uT5jnuC5P83axlH03yjSR3THJEP/+Sft0JSb6frvfGmiQP7ue3LPC6PpPk+CTHJPlykqf3634tySdmbd+S3L6ffk26YV4/keTwdB80v5UuEbA2yYuSfGTWsc7vz98xST6Z5EX9utOSXJ7knv1zn9xvv2HkuZ/vn3vEHK/jmHS9VX4lybokT+jnjx2J9UULtO/Lkry7389R6Xq6/Em/7v5J9ib5iyQbkvxskmuS3Klf/7ok/9A/7+QkFyZ5Wr/uF5NcnK5HWiW5fZLbHMC5/5Mkr0yyvn/cL0nNEffPJNk2vS7J0Umu6/d5p37d8SPX3+3mef03Oj+LxLdge82x/5YuwXpZkk3947J+Weu3qXQfmN+T5OeTHDdrH/dPctFNvGdfmOT6dPfF2v78fnqB595wnc+6Bv64b4+HJ7k2ydGLXT9z7PvX+n39Xr+vxyX5YZJj+vWPSHK7/nz8bH+c0/p1P9Vv++B09/cJSe48+j6U/dfgGbPeMy7uz/fNkrwj/ftK9r8vva5fd0S695Zr+uOsT/KcdO9rhx3AvXxskl9IcmR/Lt6W5O9HYvlUkpcmOSzJT6frQfZ3I+uf2j9vQ39eP38A1+l0O/9xkk+n6522Jcm/Zv/79IJtOEc7LdQO909/Lfav4ztJntnv9z8k2T1yPh6Q7n3ytP41/XWSj8+61j7Qn8cj5nmfPZh7c/p1/rc+nl9Psj3JG/vzetd098JtD/Re8vDw8PC4aQ89jABWl7+vqiuTfCLJx5L8jzm2eVKSv2itfbO1tjPJ85M8vuYZatBa+25rbVNr7bsHGcurW2sXttauS/LWJHfvl/9ykve21t7bWptqrX0gyTnpPhzN5+WttUtaa1ek+6B79wW2ne1drbVzW2vXJ3lXkutba69rre1L8pYks3sYvaK1tq0/1ovTJXaS7kPN/22tnd1a29dae22SXUnuNSvObf1rnu0RSb7WWnt9a21va+1NSb6S5FGLvYCqqv74v9dau6K1dnW6tn38rE3/a2ttV2vtY0n+MckvVdXadB/4n99au7q19u0kf54ucZV0H+D/tLX2b63z9dbad2a9prnO/Z4kt06XXNrTWvuX1tpcw+n+Jd2Hy/v1849N8qnW2iVJ9qX7gHqXqlrfWvt2a+0bi52PWeaL70Daa7br+308Lt25fXe/LMkNWaP/L92H4T9Pcmnfw+QOI/s4vu/xMvq42QG+lk/098W+dL2dTj3A503bk+SP+/Z4b5KdSe50ENfPqMuTvKzf11uSfDXdNZzW2j+21r7RXy8fS/L+7G/fpyU5q7X2gf7+vri19pWR/d4lXXLoBa21M2cd8/WttfNba9ck+a/Zf/1Oe2Fr7Zr+/npckn/sj7MnXYLniCT3Gdl+znu5tfb91to7WmvX9ufixekSLqmqk9IlT/9b63qQfSLddXCD1tpZ/b20K12i79Ta30tzMU9K10aXt9a2J/mj7L8Xk3nacK4dLdIOo+6VLkn98n6/70yXzBmN6azW2mf71/T8JPeuqpNHtvmT/tqZ671tPgu9b+9J8uK+7d6cZHOSv+rP6wXp/uCxWI9AAH5EEkYAq8vP98md27TW/tM8/7k/Pt1fm6d9J92HieMOcSzfG5m+Nl1vpqSr1fOLox+o0/0V/9Y3YV8H4rKR6evmmJ+9r20j099Jd76m437WrLi3jqyf/dzZZp/36f2fsHD4SbqeCEcmOXfk2O/rl0/7Qf9Be3bsm7O/h8Fcx92arjfYfOY793+WrkfH+/vhMM+b68l9kuXN2Z94e2KSN/Trvp7kd9N96L68qt48OhTmAC10nS3WXnN5XboeaDOGo428notaa89ord2uP8Y1s7a7pL8HRx/XzN7PAb6Ww+dL5M7j+621vbP2sTEHdv3MdvGsBOAN90JV/VxVfbofOnRlumTv9JDTxa6nJ6XrSfT2OdbNvvfWj+x39voZ91Nrbapff8I824/Gf2RV/d/qhmdelW4o7qY+OXV8kitaa9fOtZ+qWltVL6luqN1V6ZKHmRXnQuZ6/x29JudrwxtZpB1mH3N2ey50Lnem6/U537k8UAu9b3+/T4wm3ftwsvh7MwCHmIQRALNdku6D7rST0g0PuCxdT5CDdbDP2ZauJ8HoB+qbtdZechOOfU26D8JJkqq61U3Yx2xbR6ZPSne+ki7uF8+K+8i+p9C0hc7F7PM+vf+LDyCmHek+QN115Ni3aF2B82lHz+rJMh37jnR/zZ/d5tPH3ZZuWMtB6XsCPKu1dtt0vaR+v+aoP9R7U5LHVtVt0g0Re8fIft7YWvvpPr6W5H/Od8iDDPFA2msu/5IueXlcup5682qtbUvyvzJHrbAJcyDXz2wn9D2Tpp2U5JK+3s470vXoOa61tinJe9MNi0oWv55e2Mfzxlm9h5Ib33t7+m2njV4DM+6nPtatmXk/zXcvPytdr517ttZunm7YZPrXcGmSY6rqyJHnju7niUkek+RBSW6Rbrjc9HNnxziXud5/L5ln23kdQDuMujQ3bs/R1zT7XN4s3bC90XO50OtSqB9gmZIwAmC2NyX5veoKu25MNzTlLf1ftbcnmUpX3+hAXZbk5Jqj4PE8/i7Jo6rqof1f6w/vi6CeuOgzb+y8JHetqrv3BVVfeBP2MdtvVdWJ1RXc/YN0w9aS5G+SPL2q7lmdm1XVI6rqqAPc73uT3LGqnljd17U/Lt3wnPcs9sS+98TfJPnLqrplklTVCVX10Fmb/lFVHVZV90vyyCRv6/+K/9YkL66qo/qkze+na4ckeVWSZ1fVT/Sv6/b9NguqrqD07fsPoVelG162b65tW2ufS3dtvSrJP7fWruz3caeqekD/4ff6dEmNOfeR7jo7mOvyJrVX3wvjUUkePatHxnSx5D/qX/ea6opgPzVdTZpxO+DzcRDXz6hbJvmdqlpfVb+Y5MfSXcOHpRtGuD3J3qr6uSQPGXne3yZ5SlU9sD9HJ1TVnUfW70lXN+tmSV4/633jl6vqLn2y5o+TvH2kF8psb03yiP4469MlgXalqwk0bb57+ah019qV/boXjJyr76QbIvvC/l66d2YOGz2qP8730yWrZw/7Xaxd3pTkD6tqS3/9/LfsvxcPxmLtMOpT6e6rZ/TvPY9JV2tq2hvTtdnd+3vxfyQ5u3XDVw/Ewd6bAEwICSMAZjsrXX2Uj6crAH19kt9Okn4YxouTfLIfunKvqjqpum+/OWme/b2t//n9qvrsYgfve2U8Jt0HuO3peiT859yE31mttQvTfbD8YLpixDfp26pmeWO6WiDf7B8v6o91Tro6MK9IV6z66+mKAx9orN9Pl8R5VroPm89J8sjW2o4Fn7jfc/tjfrofCvPBzKxt8r0+rkvSDfl6+kjtmN9O1xvrm+nO0RvTXQdprb0tXZu/McnVSf4+XZHaxdyhj2Fnug+k/7u19tEFtn9Tul4ZbxxZtiHJS9L1IvleuiTFfN+O9Lfpah1dWVV/v1hwP0p7tdYu6OuozLY7XY+SD6ZLkp2fLnkwut/j+/tl9PELB3Lcg/TCJK/tz8cvHcD2i10/s52dro13pLs+HtvX/rk6ye+kS9j8IF2Pmxtq/LTWPpPkKUn+Ml3x649lVs+61trudIWXb5nkrJGk0evTFVD+Xroi9b8zX3Ctta+mq4f2132Mj0ryqH7f0+a8l9MVqj6if96n0w3PG/WkJPdOd5++KF2iaVe/7nXphm9dnORLuXGycLHr9EXpElJfSPLFJJ8dieuALdYOs7adPt9PS/cFBr+cLlG9q1//oXQ1o96RrjfS7bJwfavZDureBGByVJuz/iQAsFJU1f3TfYvTTemlBYOrqo+mu4ZfdYj29+103wz5wUOwr7ck+Upr7QWLbrxMVNXZSV7ZWnv10LEAMBw9jAAA4ABV1U9W1e36IXUPS9cjcln3nKmqn62qW/VD0p6c7hvIZvesAmCVOZhv1gAAgNXuVknema7w80VJfrOvw7Wc3Snd8LWN6b7F7rGttUuHDQmAoRmSBgAAAMAMhqQBAAAAMIOEEQAAAAAzLIsaRps3b24nn3zy0GEAAAAArBjnnnvujtbalrnWLYuE0cknn5xzzjln6DAAAAAAVoyq+s586wxJAwAAAGAGCSMAAAAAZpAwAgAAAGAGCSMAAAAAZpAwAgAAAGAGCSMAAAAAZpAwAgAAAGAGCSMAAAAAZpAwGqMdO3flQ1++LDt27ho6FAAAAIB5rRs6gNVix85deeBLP5o9U1M5bO3afPBZP5vNGzcMHRYAAADAjehhNCbnbbsyV12/N9funsrufVM5b9uVQ4cEAAAAMCcJozGpSlo/fe3ufdl4uM5dAAAAwGSSMBqTs7/x/Rnzn/zajoEiAQAAAFiYhNGY/MLpW2+YriSPPPX44YIBAAAAWICE0Zjc8bij8u/vcUIOW7sm//x7P5M7HnfU0CEBAAAAzEnCaIyOPvKwHLZujWQRAAAAMNEkjMaoaugIAAAAABa3ZAmjqjqrqi6vqvPnWPfsqmpVtXmpjj+pWmuLbwQAAAAwoKXsYfSaJA+bvbCqtiZ5cJLvLuGxJ5IORgAAAMBysGQJo9bax5NcMceqv0zynCSrsqvNqnzRAAAAwLIy1hpGVfXoJBe31s4b53EnRVViRBoAAAAw6daN60BVdWSS/5LkIQe4/RlJzkiSk046aQkjG59S9RoAAABYBsbZw+h2SU5Jcl5VfTvJiUk+W1W3mmvj1tqZrbXTW2unb9myZYxhLq1mUBoAAAAw4cbWw6i19sUkt5ye75NGp7fWdowrhqHpXwQAAAAsB0vWw6iq3pTkU0nuVFUXVdXTlupYy4kaRgAAAMCkW7IeRq21Jyyy/uSlOvbE0sUIAAAAWAbG+i1pRAUjAAAAYOJJGI1RpWSMAAAAgIknYTRGZUgaAAAAsAxIGI1Z08UIAAAAmHASRmOkgxEAAACwHEgYjVnTwQgAAACYcBJGY6SGEQAAALAcSBiNmQ5GAAAAwKSTMBqjSqUZkwYAAABMOAmjMTIkDQAAAFgOJIzGTP8iAAAAYNJJGI2RDkYAAADAciBhNGZKGAEAAACTTsJonBQxAgAAAJYBCaMxki4CAAAAlgMJowE049IAAACACSZhNEZGpAEAAADLgYTRAHQwAgAAACaZhNEYlSpGAAAAwDIgYTQAHYwAAACASSZhNEbTNYwUvQYAAAAmmYTRGBmQBgAAACwHEkYD0L8IAAAAmGQSRmNUuhgBAAAAy4CE0QCUMAIAAAAm2ZIljKrqrKq6vKrOH1n2Z1X1lar6QlW9q6o2LdXxJ1HpYgQAAAAsA0vZw+g1SR42a9kHktyttfbjSS5M8vwlPP7EaqoYAQAAABNsyRJGrbWPJ7li1rL3t9b29rOfTnLiUh1/khmSBgAAAEyyIWsYPTXJPw14/LEzIg0AAABYDgZJGFXVf0myN8kbFtjmjKo6p6rO2b59+/iCAwAAAFjlxp4wqqonJ3lkkie1Nv/grNbama2101trp2/ZsmV8AS6hii5GAAAAwORbN86DVdXDkjw3yc+21q4d57EniRpGAAAAwCRbsh5GVfWmJJ9KcqequqiqnpbkFUmOSvKBqvp8Vb1yqY4/idQwAgAAAJaDJeth1Fp7whyL/3apjrectOhiBAAAAEyuIb8lbdWZ7mBkSBoAAAAwySSMxsiQNAAAAGA5kDAagA5GAAAAwCSTMBqjii5GAAAAwOSTMBpAU8QIAAAAmGASRmOkhhEAAACwHEgYDUD/IgAAAGCSSRgNwIg0AAAAYJJJGI1RGZMGAAAALAMSRkPQwwgAAACYYBJGY6R/EQAAALAcSBgNoOliBAAAAEwwCaMxmi5hpOg1AAAAMMkkjAAAAACYQcJojKZrGOlgBAAAAEwyCaMxqlL2GgAAAJh8EkYDaIoYAQAAABNMwmiMdDACAAAAlgMJowHoXwQAAABMMgmjMbqh6LWMEQAAADDBJIzGyZg0AAAAYBmQMBpAMygNAAAAmGASRmOkfxEAAACwHEgYDUEHIwAAAGCCSRiNkRJGAAAAwHKwZAmjqjqrqi6vqvNHlh1TVR+oqq/1P49equNPMh2MAAAAgEm2lD2MXpPkYbOWPS/Jh1prd0jyoX5+1ai+ilGTMQIAAAAm2JIljFprH09yxazFj0ny2n76tUl+fqmOP4kMSQMAAACWg3HXMDqutXZpkvQ/bznm40+EZlAaAAAAMMEmtuh1VZ1RVedU1Tnbt28fOpxDQgcjAAAAYDkYd8Losqq6dZL0Py+fb8PW2pmttdNba6dv2bJlbAGOgxpGAAAAwCQbd8Lo3Ume3E8/Ock/jPn4g1LDCAAAAFgOlixhVFVvSvKpJHeqqouq6mlJXpLkwVX1tSQP7udXHR2MAAAAgEm2bql23Fp7wjyrHrhUx5x01VcxasakAQAAABNsYoter0iGpAEAAADLgITRAHQwAgAAACaZhNEY6WAEAAAALAcSRgAAAADMIGE0RlX6GAEAAACTT8JoAGoYAQAAAJNMwmiMpvsXtcgYAQAAAJNLwmiMjEgDAAAAlgMJowEYkgYAAABMMgmjMdLDCAAAAFgOJIwGoIMRAAAAMMkkjMaooosRAAAAMPkkjAbQFDECAAAAJpiE0RhN1zCSLgIAAAAmmYQRAAAAADNIGA3AiDQAAABgkkkYjVGVotcAAADA5JMwGoQuRgAAAMDkkjAao+n+RYakAQAAAJNMwmiMjEgDAAAAlgMJowHoYAQAAABMMgmjMaroYgQAAABMPgmjAahhBAAAAEwyCaMxUsMIAAAAWA4kjAbQVDECAAAAJtggCaOq+r2quqCqzq+qN1XV4UPEMW7THYwMSQMAAAAm2dgTRlV1QpLfSXJ6a+1uSdYmefy44xiCIWkAAADAcjDUkLR1SY6oqnVJjkxyyUBxjNVV1+9Nkvzg2t0DRwIAAAAwv7EnjFprFyd5aZLvJrk0yQ9ba++fvV1VnVFV51TVOdu3bx93mIfcjp278sJ3X5Ak+Y3XnZsdO3cNHBEAAADA3IYYknZ0ksckOSXJ8UluVlW/PHu71tqZrbXTW2unb9myZdxhHnLnbbsyU1Nd8aK9U1M5b9uVA0cEAAAAMLchhqQ9KMm3WmvbW2t7krwzyX0GiGOsTt26KWvXdEWM1q5Zk1O3bho4IgAAAIC5DZEw+m6Se1XVkVVVSR6Y5MsDxDFWmzduyIv/w79LkrziiffI5o0bBo4IAAAAYG4LJoxGh4pV1X1nrXvGTTlga+3sJG9P8tkkX+xjOPOm7Gu5OfrIw5IkRx2+buBIAAAAAOa3WA+j3x+Z/utZ6556Uw/aWntBa+3OrbW7tdZ+pbW2KipAr61uSNq+qYEDAQAAAFjAYgmjmmd6rnkWsaY/2/v64tcAAAAAk2ixhFGbZ3queRaxrs8YTTWnDgAAAJhcixXTuXNVfSFdb6Lb9dPp52+7pJGtQGv79NxePYwAAACACbZYwujHxhLFKrGmr2E0JWEEAAAATLAFE0atte+MzlfVsUl+Jsl3W2vnLmVgK9HaNdNFryWMAAAAgMm1YA2jqnpPVd2tn751kvPTfTva66vqd8cQ34oy3cNonxpGAAAAwARbrOj1Ka218/vppyT5QGvtUUnumS5xxEGY7mFkSBoAAAAwyRZLGO0ZmX5gkvcmSWvt6iRTSxXUSrWuTxgpeg0AAABMssWKXm+rqt9OclGS05K8L0mq6ogk65c4thVnzXQPI0PSAAAAgAm2WA+jpyW5a5JfS/K41tqV/fJ7JXn1Esa1Iq0tRa8BAACAybfYt6RdnuTpcyz/SJKPLFVQK5VvSQMAAACWgwUTRlX17oXWt9YefWjDWdkMSQMAAACWg8VqGN07ybYkb0pydpJa8ohWsOmi1/98/vdyj5OOzh2PO2rgiAAAAABubLEaRrdK8gdJ7pbkr5I8OMmO1trHWmsfW+rgVppv77gmSfLhr27PQ//y47nwsqsHjggAAADgxhZMGLXW9rXW3tdae3K6QtdfT/LR/pvTOEgf/NJlN0y3JO8575LhggEAAACYx2JD0lJVG5I8IskTkpyc5OVJ3rm0Ya1Mdznh5jPmTzr2yIEiAQAAAJjfYkWvX5tuONo/Jfmj1tr5Y4lqhfrW9mtmzP+Xd52f+9/pltm8ccNAEQEAAADc2GI1jH4lyR2TPDPJv1bVVf3j6qq6aunDW1keeerxM+bXVHLetisHigYAAABgbovVMFrTWjuqf9x85HFUa+3mCz2XG7vjcUflzF/9iRvmr98zla3HGJYGAAAATJbFehhxiK2tSlU3ffj6Ndl2xbXDBgQAAAAwi4TRmG095si01k3rYQQAAABMIgmjMdt2xbVZ15/1DetKDyMAAABg4kgYjdnWY47M3qlu+vq9TQ8jAAAAYOJIGI3ZtiuuzYa+i9GGdWoYAQAAAJNnkIRRVW2qqrdX1Veq6stVde8h4hjCqVs3Zf3a/addDyMAAABg0gzVw+ivkryvtXbnJKcm+fJAcYzd5o0b8je/+hNJkqnW8kuv/FR27Nw1cFQAAAAA+409YVRVN0/yM0n+Nklaa7tba1eOO44h7bx+b5Jkz76W3fv25bxtq+rlAwAAABNuiB5Gt02yPcmrq+pzVfWqqrrZAHEM5jab97/c63ZPGZYGAAAATJQhEkbrkpyW5P+01u6R5Jokz5u9UVWdUVXnVNU527dvH3eMS2rbFdemqps+4rC1Cl8DAAAAE2WIhNFFSS5qrZ3dz789XQJphtbama2101trp2/ZsmWsAS61U7duytqqVJJ1ayqnbt00dEgAAAAANxh7wqi19r0k26rqTv2iByb50rjjGFpV0oYOAgAAAGAOQ31L2m8neUNVfSHJ3ZP8j4HiGMRoket9U1OKXgMAAAATZd0QB22tfT7J6UMcexJMD0nbk5Z1a9YYkgYAAABMlKF6GK1qmzduyDMecPskycufeI9s3rhh4IgAAAAA9pMwGsCOnbvyfz76jSTJb73hs9mxc9fAEQEAAADsJ2E0gPO2XZmp1pW83jvV1DACAAAAJoqE0QBO3bop69Z0p75NtWw95siBIwIAAADYT8JoAJs3bsirfq2r+T2V5Jde+SnD0gAAAICJIWE0kCuv3Z0k2bOvZe/UlGFpAAAAwMSQMBrIT9zmmCTJ+rWVdWvW5NStmwaOCAAAAKCzbugAVqvNGzfkuJtvyKYjDstfP/Ee2bxxw9AhAQAAACTRw2gwO3buyo6rd+fr269WwwgAAACYKBJGA+lqFrXsm4oaRgAAAMBEMSRtIKdu3ZQ1VWlpahgBAAAAE0UPo4Fs3rghD7zLcTli/dq89en3VsMIAAAAmBgSRgPZsXNXPvKVy3PN7n1qGAEAAAATRcJoIOdtuzKttSTJnn371DACAA30uBQAABQMSURBVAAAJoaE0UBO3bopa9dUkmStGkYAAADABJEwGsjmjRvyvJ/7sSTJ6576U2oYAQAAABNDwmhAGw/vvqTu6l17B44EAAAAYD8Jo4Hs2LkrL/j785MkT3/9uYpeAwAAABNDwmgg5227Mvv6otf7ppqi1wAAAMDEkDAayKlbN2X9mu70V5Wi1wAAAMDEkDAayOaNG/Lu3/7pJMlD7nrcwNEAAAAA7CdhNKAjN6xNkrz3i5fmQX/+MXWMAAAAgIkgYTSgL170wyTJnn0te6em1DECAAAAJsK6oQNYzU7duilVydqqrFuzRh0jAAAAYCJIGA1o88YNucMtN+bIw9blVU8+PZs3bhg6JAAAAIDhhqRV1dqq+lxVvWeoGCbBxg3rct3uvUOHAQAAAHCDIWsYPTPJlwc8/uB27NyVL1z0w3zt8p2KXgMAAAATY5CEUVWdmOQRSV41xPEnxXSR66kWRa8BAACAiTFUD6OXJXlOkqmBjj8RTt26KWuqkkTRawAAAGBijD1hVFWPTHJ5a+3cRbY7o6rOqapztm/fPqboxmvzxg35xdNPTJK8+Tfupeg1AAAAMBGG6GF03ySPrqpvJ3lzkgdU1d/N3qi1dmZr7fTW2ulbtmwZd4xjsWPnrrzj3IuSJI975afUMAIAAAAmwtgTRq2157fWTmytnZzk8Uk+3Fr75XHHMQnO23ZlWlqSZI8aRgAAAMCEGPJb0la9U7duyto1XROsLTWMAAAAgMkwaMKotfbR1tojh4xhSJs3bsifPfbHkyRPvu9tBo4GAAAAoKOH0cCOOnx9kuRVH/9WHvTnH1PHCAAAABichNHALvrBtUmS6/dOZa86RgAAAMAEkDAa2E+efEySZN2aypoqdYwAAACAwUkYDWzj4euGDgEAAABgBgmjgX3pkquSJHunmiFpAAAAwESQMBrY1mOOvGH62t1TM+YBAAAAhiBhNLALLv7hgvMAAAAA4yZhNLSaOXvpVdcNEwcAAABAT8JoYPe7w5ZsWLc/a/Sn77swF1529YARAQAAAKudhNHANm/ckIff7dYzlv3emz+XHTt3DRQRAAAAsNpJGE2AIzesmzF/waVX5ydf9MG8/dxtA0UEAAAArGYSRhPgyfc5+UbLWpJnv+0LecWHvzb2eAAAAIDVTcJoAtzxuKPygkfdZc51L33/hXoaAQAAAGMlYTQhnnLfU/Lsh9xxznXPftsXFMIGAAAAxkbCaII84wF3yFt+4145/hYbbrTurz7w1QEiAgAAAFYjCaMJc89Tjs27f/t+WTerZf7x/Mv0MgIAAADGQsJoAm3euCFv+PV73Wj5az/5rQGiAQAAAFYbCaMJdc9Tjs1Tf/o2M5a9/bMXZcfOXQNFBAAAAKwWEkYT7N+dsGnG/K69Lf9y4faBogEAAABWCwmjCXa/O2zJhrU1Y9nVu/YMFA0AAACwWkgYTbDNGzfkmQ++44xlO3ftHSgaAAAAYLWQMJpwt77F4TPm//pDX1fHCAAAAFhSEkYTrhuWtn/+uj1T6hgBAAAAS0rCaMJ1w9LuNGOZOkYAAADAUpIwWgY2jnYxijpGAAAAwNIae8KoqrZW1Ueq6stVdUFVPXPcMSw3Rx2+fsa8OkYAAADAUhqih9HeJM9qrf1Yknsl+a2qussAcSwb6hgBAAAA4zT2hFFr7dLW2mf76auTfDnJCeOOYzlRxwgAAAAYp0FrGFXVyUnukeTsIeNYDm59i8NnzM8epgYAAABwqAyWMKqqjUnekeR3W2tXzbH+jKo6p6rO2b7d8Ku7Hn+LGfPHbzpioEgAAACAlW6QhFFVrU+XLHpDa+2dc23TWjuztXZ6a+30LVu2jDfACbTtimuzYW3dMP+Usz6j8DUAAACwJIb4lrRK8rdJvtxa+4txH3+5OnXrpqzZny/KtQpfAwAAAEtkiB5G903yK0keUFWf7x8PHyCOZWXzxg15/iNmfZlczb0tAAAAwI9i3bgP2Fr7RKQ6bpJ73fbYGfOz6xoBAAAAHAqDfksaB+eCi3+44DwAAADAoSBhtJzM6pd19a49w8QBAAAArGgSRsvI/e6wJUes399kL/3nC31TGgAAAHDISRgtI5s3bsgLHrW/8PXeqamct+3KASMCAAAAViIJo2XmtNscc8P0tbunsvWYIweMBgAAAFiJJIyWGYWvAQAAgKUmYbTc1CLzAAAAAD8iCaNl5q7H32LBeQAAAIAflYTRMrPtimtz2NquW9H6tWVIGgAAAHDISRgtM6du3ZT1a7tm27Ov5QXvviA7du4aOCoAAABgJZEwWmY2b9yQ5/7cnW6Y3zs1lfO2XTlgRAAAAMBKI2G0DN3zlGNvmL5u91S2HnPkgNEAAAAAK42E0TJ00Q+uu+HL0Y44bG22XXHtoPEAAAAAK4uE0TJ06tZNWbOmUknWramcunXT0CEBAAAAK4iE0TK1ppI2dBAAAADAiiRhtAyNFrnes2+fotcAAADAISVhtAxtPebI7NnX9S+6bk9T9BoAAAA4pCSMlqFtV1ybDeu6plu/pnLBxT8cOCIAAABgJZEwWoZO3bop69d235O2Z6rlBe++IDt27ho4KgAAAGClkDBahjZv3JAXPvquN8xPtaaOEQAAAHDIrBs6AG6a+9/plql+eueufXne27+QwzeszY+feIs884F3zB2PO2rQ+AAAAIDlS8JomWv9z+3X7E6uSbZdcV3+8Qvfy7FHrs+6vs7REYetzSN//Nb5tfucks0bNwwXLAAAALAsSBgtU/9y4fYbkkVz+f61e2bMv+LD38grPvyNbLnZYVnT1z866vB1ec7D7pyH3OVWSxgpAAAAsNxIGC1TV+/as/hGc9h+ze4bpi+7alfOeN25ufmGNTliw/oZ261dUzl8feX63VPZN0dmSq8lAAAAWLkkjJapow6fmeA5akPl6l0L9Tma31W7pnLVroP/lrXpXktHH7E+a9dWV1OpckNtpapuarHk08E6lPu7qfuSMAMAAGAlGyRhVFUPS/JXSdYmeVVr7SVDxLGc3e8OW3Lzw9dl996pHLZuTT787PsnSV79iW/mH794aa7bM5Uk2b1nX35w3d4ljeUH19203k7L3XTC7BaHr8uaNZU1ayob1iW797RMtezPnI240aKquTabkciammP9XM+Zudv9W0xCgs2+ht/X2jWV4zcdnv/80Dvnnqcc+6MFAwAArHjV2iHo8nEwB6xam+TCJA9OclGSf0vyhNbal+Z7zumnn97OOeecMUW4fOzYuSvnbbsyp27dtGAvl7O/9f382fu+kkuuvO6GD5rX796bH16/b0yRApPk5hvW5maHr83uvX1ycx51wz/zW7umcti6yu49Uwvua/9O9+9wvmTphnWVXXtmJsbmDGOB2CrJmj7JtusAkmyjSda5TFLyz77saznua5Jjsy/7sq8fbV+THJt92ddS7Gul/SG2qs5trZ0+57oBEkb3TvLC1tpD+/nnJ0lr7U/me46E0dJ4/5e+lz/9py/n6l03ThwtdCONo9cSAAAATLK3/Ma9ln3SaKGE0RBD0k5Ism1k/qIk95y9UVWdkeSMJDnppJPGE9kq85C73Oomf0PaXL2W5rPS/oIhYQYAAMDffeo7yz5htJAhEkZz9fu/0Uf11tqZSc5Muh5GSx0UB+eepxybt//mfYcOYzBzJcyGTmTZl33NZ2qqZfvO3YtvCAAAHLBfvvdthg5hSQ2RMLooydaR+ROTXDJAHHCTrfaEGcvPjp27biiKv3tfm4hE1lLvz77sy74mZ1+THJt92Zd9/Wj7muTY7Mu+lmJfK62G0UKGqGG0Ll3R6wcmuThd0esnttYumO85ahgBAAAAHFoTVcOotba3qp6R5J+TrE1y1kLJIgAAAADGa4ghaWmtvTfJe4c4NgAAAAALWzN0AAAAAABMFgkjAAAAAGaQMAIAAABgBgkjAAAAAGaQMAIAAABgBgkjAAAAAGaQMAIAAABghmqtDR3Doqpqe5LvDB3HIbI5yY6hg2DstPvqpe1XL22/Omn31Uvbr17afnXS7qvXSmv727TWtsy1YlkkjFaSqjqntXb60HEwXtp99dL2q5e2X520++ql7Vcvbb86affVazW1vSFpAAAAAMwgYQQAAADADBJG43fm0AEwCO2+emn71Uvbr07affXS9quXtl+dtPvqtWraXg0jAAAAAGbQwwgAAACAGSSMxqSqHlZVX62qr1fV84aOh0Ovqr5dVV+sqs9X1Tn9smOq6gNV9bX+59H98qqql/fXwxeq6rRho+dgVNVZVXV5VZ0/suyg27qqntxv/7WqevIQr4UDN0+7v7CqLu7v+89X1cNH1j2/b/evVtVDR5b7fbDMVNXWqvpIVX25qi6oqmf2y933K9gC7e6+X+Gq6vCq+kxVnde3/R/1y0+pqrP7+/ctVXVYv3xDP//1fv3JI/ua85pg8izQ7q+pqm+N3PN375d7r19hqmptVX2uqt7Tz7vnW2seS/xIsjbJN5LcNslhSc5Lcpeh4/I45O387SSbZy370yTP66efl+R/9tMPT/JPSSrJvZKcPXT8HgfV1j+T5LQk59/Utk5yTJJv9j+P7qePHvq1eRx0u78wybPn2PYu/Xv9hiSn9L8D1vp9sDwfSW6d5LR++qgkF/Zt7L5fwY8F2t19v8If/b27sZ9en+Ts/l5+a5LH98tfmeQ3++n/lOSV/fTjk7xloWti6NfncdDt/pokj51je+/1K+yR5PeTvDHJe/r5VX/P62E0Hj+V5OuttW+21nYneXOSxwwcE+PxmCSv7adfm+TnR5a/rnU+nWRTVd16iAA5eK21jye5Ytbig23rhyb5QGvtitbaD5J8IMnDlj56bqp52n0+j0ny5tbartbat5J8Pd3vAr8PlqHW2qWttc/201cn+XKSE+K+X9EWaPf5uO9XiP7e3dnPru8fLckDkry9Xz77np9+L3h7kgdWVWX+a4IJtEC7z8d7/QpSVScmeUSSV/XzFfe8hNGYnJBk28j8RVn4PxwsTy3J+6vq3Ko6o192XGvt0qT7j2eSW/bLXRMrz8G2tWtg5XhG3xX9rOkhSdHuK1bf7fwe6f7y7L5fJWa1e+K+X/H6oSmfT3J5ug/830hyZWttb7/JaDve0Mb9+h8mOTbaftmZ3e6ttel7/sX9Pf+XVbWhX+aeX1leluQ5Sab6+WPjnpcwGpOaY5mvp1t57ttaOy3JzyX5rar6mQW2dU2sHvO1tWtgZfg/SW6X5O5JLk3y5/1y7b4CVdXGJO9I8ruttasW2nSOZdp/mZqj3d33q0BrbV9r7e5JTkzXQ+DH5tqs/6ntV4jZ7V5Vd0vy/CR3TvKT6YaZPbffXLuvEFX1yCSXt9bOHV08x6ar7p6XMBqPi5JsHZk/McklA8XCEmmtXdL/vDzJu9L95+Ky6aFm/c/L+81dEyvPwba1a2AFaK1d1v/ncirJ32R/t2PtvsJU1fp0SYM3tNbe2S92369wc7W7+351aa1dmeSj6WrUbKqqdf2q0Xa8oY379bdIN4RZ2y9TI+3+sH54amut7Ury6rjnV6L7Jnl0VX073bDhB6TrcbTq73kJo/H4tyR36KusH5auMNa7B46JQ6iqblZVR01PJ3lIkvPTtfP0NyM8Ock/9NPvTvKr/bcr3CvJD6eHNbBsHWxb/3OSh1TV0f1whof0y1hGZtUe+/fp7vuka/fH99+icUqSOyT5TPw+WJb6ugR/m+TLrbW/GFnlvl/B5mt39/3KV1VbqmpTP31Ekgelq2H1kSSP7Tebfc9Pvxc8NsmHW2st818TTKB52v0rI38YqHQ1bEbvee/1K0Br7fmttRNbayene4/+cGvtSXHPZ93im/Cjaq3trapnpHujWJvkrNbaBQOHxaF1XJJ3db9Hsi7JG1tr76uqf0vy1qp6WpLvJvnFfvv3pvtmha8nuTbJU8YfMjdVVb0pyf2TbK6qi5K8IMlLchBt3Vq7oqr+e7oPEknyx621Ay2ozADmaff7V/f1ui3dNyX+RpK01i6oqrcm+VKSvUl+q7W2r9+P3wfLz32T/EqSL/a1LZLkD+K+X+nma/cnuO9XvFsneW1VrU33B/a3ttbeU1VfSvLmqnpRks+lSyim//n6qvp6ul4Gj08WviaYSPO1+4eraku64UafT/L0fnvv9Svfc7PK7/nqEmEAAAAA0DEkDQAAAIAZJIwAAAAAmEHCCAAAAIAZJIwAAAAAmEHCCAAAAIAZJIwAAOZQVfuq6vMjj+cdwn2fXFXnH6r9AQAcauuGDgAAYEJd11q7+9BBAAAMQQ8jAICDUFXfrqr/WVWf6R+375ffpqo+VFVf6H+e1C8/rqreVVXn9Y/79LtaW1V/U1UXVNX7q+qIwV4UAMAsEkYAAHM7YtaQtMeNrLuqtfZTSV6R5GX9slckeV1r7ceTvCHJy/vlL0/ysdbaqUlOS3JBv/wOSf5Xa+2uSa5M8gtL/HoAAA5YtdaGjgEAYOJU1c7W2sY5ln87yQNaa9+sqvVJvtdaO7aqdiS5dWttT7/80tba5qranuTE1tqukX2cnOQDrbU79PPPTbK+tfaipX9lAACL08MIAODgtXmm59tmLrtGpvdFbUkAYIJIGAEAHLzHjfz8VD/9r0ke308/Kckn+ukPJfnNJKmqtVV183EFCQBwU/lLFgDA3I6oqs+PzL+vtfa8fnpDVZ2d7o9vT+iX/U6Ss6rqPyfZnuQp/fJnJjmzqp6WrifRbya5dMmjBwD4EahhBABwEPoaRqe31nYMHQsAwFIxJA0AAACAGfQwAgAAAGAGPYwAAAAAmEHCCAAAAIAZJIwAAAAAmEHCCAAAAIAZJIwAAAAAmEHCCAAAAIAZ/n9DhG6JM/Vb5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize = (20,5))\n",
    "plt.scatter(epoch,obj, s  = 7)\n",
    "plt.plot(epoch,obj)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title('Plot: the number of epochs vs the MSE in the backpropagation algorithm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,5))\n",
    "plt.scatter(x,d, s  = 7)\n",
    "plt.scatter(x,y, c = 'r', s = 15)\n",
    "plt.xlabel(\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# #np.random.seed(100)\n",
    "\n",
    "# # hyperbolic Activation Function\n",
    "# def af(t):\n",
    "#     return tanh(t)\n",
    "\n",
    "# # Derivative of tanh(v)\n",
    "# def af_derivative(x):\n",
    "#     return 1-(tanh(x)**2)\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i]             \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(af(l))\n",
    "#             p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         #print(w[nLayers][\"weights\"][0])\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         c += (d[i] - y)**2            \n",
    "#     return c/n\n",
    "\n",
    "# def weights_Initialization(x,numLayers,numNodes, numOutputs):\n",
    "\n",
    "#     weights = [{\"weights\":np.random.rand(numNodes, len(x[0]))}] \n",
    "#     for i in range(numLayers-1):\n",
    "#         weights.append({\"weights\":np.random.rand(numNodes,numNodes+1)})             \n",
    "#     if numLayers >= 0:            \n",
    "#         weights.append({\"weights\":np.random.rand(numOutputs,numNodes+1)})\n",
    "#     return weights\n",
    "\n",
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "    \n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, weights = 0, eta=0.001,maxIter=10000, ep = 0):\n",
    "#         self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.weights = weights\n",
    "#         self.eta = eta\n",
    "#         self.temp_eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         self.ep = ep\n",
    "#         #self.train()\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "# #         newdata = []\n",
    "# #         for i in range(len(x)):\n",
    "# #             newdata.append(np.append(x[i],1))     \n",
    "        \n",
    "\n",
    "        \n",
    "          \n",
    "        \n",
    "#     def train(self):\n",
    "#         print(self.weights)\n",
    "#         temp_weights = self.weights\n",
    "#         temp_eta = self.temp_eta\n",
    "#         temp2 = mse(self.data, self.labels, self.weights, self.nLayers, self.nNodes)\n",
    "#         print(temp2)\n",
    "#         e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "#         cos = 100000000\n",
    "#         while cos >= self.ep and e <= self.maxIt:\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 self.backprop(self.labels[i], self.data[i]) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "\n",
    "#             cos = mse(self.data, self.labels, self.weights, self.nLayers,self.nNodes)\n",
    "# #             epoch.append(e)\n",
    "# #             obj.append(cos)\n",
    "# #             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 cos = 100000000\n",
    "#                 self.weights = temp_weights\n",
    "#                 print(temp_weights)\n",
    "#                 print(f)\n",
    "                \n",
    "#                 if self.eta <= 0.00001:                    \n",
    "#                     self.eta = temp_eta  \n",
    "# #                     obj =[]\n",
    "# #                     epoch = []\n",
    "# #                     e = 0\n",
    "# #                     cos = 100000000\n",
    "#                     self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}]\n",
    "#                     for i in range(self.nLayers-1):\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)})\n",
    "#                     if self.nLayers > 0:\n",
    "#                         self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)})                    \n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "#         return self.weights, obj, epoch   \n",
    "       \n",
    "\n",
    "#     def feedforward(self,x=[]):\n",
    "#         prev = x\n",
    "#         r =[]      \n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))           \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], l)\n",
    "#         s.append(p)\n",
    "#         t.append(s)              \n",
    "#         return t,r, p        \n",
    "\n",
    "#     def backprop(self, d, data):\n",
    "#         der = []\n",
    "#         #t,r= self.feedforward(data)\n",
    "# #         print('\\n')\n",
    "# #         print(\"t = \" + str(t))\n",
    "# #         print('\\n')\n",
    "# #         print('r = ' + str(r))  \n",
    "#         t,r,q = self.feedforward(data)\n",
    "        \n",
    "#         for i in range(self.nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(self.nNodes):\n",
    "#                 a.append(af_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = []\n",
    "#         s =[]\n",
    "#         s.append(af_derivative(t[nLayers][0]))\n",
    "#         diff.append(d - q)\n",
    "#         der.append(s)\n",
    "#         for i in reversed(range(len(self.weights))):\n",
    "#             layer = self.weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(self.weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "                    \n",
    "#                     for k in range(len(self.weights[i + 1]['weights'])):\n",
    "#                         error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff[0])\n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "\n",
    "#         for j in range(len(self.weights)):\n",
    "#             layer = self.weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(self.weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(self.weights[j]['weights'][k])):\n",
    "#                     s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hyperbolic Activation Function\n",
    "# def af(t):\n",
    "#     return tanh(t)\n",
    "\n",
    "# # Derivative of tanh(v)\n",
    "# def af_derivative(x):\n",
    "#     return 1-(tanh(x)**2)\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i] \n",
    "            \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(tanh(l))\n",
    "#             p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         c += (d[i] - y)**2\n",
    "            \n",
    "#     return c/n\n",
    "\n",
    "\n",
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "    \n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000):\n",
    "#         self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         self.weights = [{\"weights\":np.random.rand(numNodes, len(x[0]))}] #create the weights from the inputs to the first layer\n",
    "#         for i in range(self.nLayers-1):\n",
    "#             self.weights.append({\"weights\":np.random.rand(numNodes,numNodes+1)}) #create the random weights between internal layers\n",
    "            \n",
    "#         if self.nLayers >= 0:\n",
    "            \n",
    "#             self.weights.append({\"weights\":np.random.rand(numOutputs,numNodes+1)}) #create weights from final layer to output node\n",
    "#         self.outputs = np.zeros(y.shape)\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "#     def train(self):\n",
    "#         print(len(self.data))\n",
    "#         print(self.weights)\n",
    "#         print(mse(self.data, self.labels, self.weights, self.nLayers, self.nNodes))\n",
    "#         t = self.weights\n",
    "#         temp_eta = self.eta\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "#         e = 0\n",
    "# #         epoch.append(e)\n",
    "# #         obj.append(mse(self.data, self.labels, self.weights, self.nLayers,self.nNodes))\n",
    "#         cos = 100000000\n",
    "#         while e < self.maxIt:\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 self.backprop(self.labels[i], self.data[i], self.weights, self.nLayers, self.nNodes) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "\n",
    "\n",
    "#             cos = mse(self.data, self.labels, self.weights, self.nLayers,self.nNodes)\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 if self.eta <= 0.00001:\n",
    "#                     self.eta = temp_eta\n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 #epoch.append(e)\n",
    "#                 #self.weights = t\n",
    "#                 #temp = mse(self.data, self.labels, t, self.nLayers,self.nNodes)\n",
    "#                 #obj.append(temp)\n",
    "#                 #print(temp)                \n",
    "#                 cos = 100000000\n",
    "#                 prev = 0\n",
    "\n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 epd = abs(cos - prev)\n",
    "#                 e += 1\n",
    "#                 #print(g)\n",
    "\n",
    "#         return self.weights, obj, epoch    \n",
    "       \n",
    "#     def predict(self,x=[]):\n",
    "#         prev = x\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 s.append(np.dot(self.weights[j][\"weights\"][m], prev))\n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             prev = np.asarray(l)\n",
    "#         s =[]\n",
    "#         l.append(1)\n",
    "#         prev = np.asarray(l)\n",
    "#         p = np.dot(self.weights[self.nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         #q = af(p)\n",
    "#         return p\n",
    "\n",
    "#     def feedforward(self, data, weights, nLayers, nNodes):\n",
    "#         r =[]\n",
    "#         prev = data\n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(nNodes):\n",
    "#                 s.append(np.dot(weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         l.append(1)\n",
    "#         p = np.dot(weights[nLayers][\"weights\"][0], l)\n",
    "#         s.append(p)\n",
    "#         #p = sigmoid(p)\n",
    "#         t.append(s)        \n",
    "        \n",
    "#         return t,r\n",
    "\n",
    "#     def backprop(self, d, data, weights, nLayers, nNodes):\n",
    "#         der = []\n",
    "#         t,r = self.feedforward(data, weights, nLayers, nNodes)\n",
    "# #         print('\\n')\n",
    "# #         print(\"t = \" + str(t))\n",
    "# #         print('\\n')\n",
    "# #         print('r = ' + str(r))  \n",
    "#         q = self.predict(data)\n",
    "        \n",
    "#         for i in range(nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(nNodes):\n",
    "#                 a.append(af_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = []\n",
    "#         s =[]\n",
    "#         s.append(af_derivative(t[nLayers][0]))\n",
    "#         diff.append(d - q)\n",
    "#         der.append(s)\n",
    "#         for i in reversed(range(len(weights))):\n",
    "#             layer = weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "                    \n",
    "#                     for k in range(len(weights[i + 1]['weights'])):\n",
    "#                         error += (weights[i + 1]['weights'][k][j] * weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff[0])\n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "\n",
    "#         for j in range(len(weights)):\n",
    "#             layer = self.weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(self.weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(self.weights[j]['weights'][k])):\n",
    "#                     s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hyperbolic Activation Function\n",
    "# def af(t):\n",
    "#     return tanh(t)\n",
    "\n",
    "# # Derivative of tanh(v)\n",
    "# def af_derivative(x):\n",
    "#     return 1-(tanh(x)**2)\n",
    "\n",
    "# def mse(x, d, w, nLayers, nNodes):\n",
    "#     c = 0\n",
    "#     n = len(x)\n",
    "#     for i in range(0,n):\n",
    "#         prev = x[i] \n",
    "            \n",
    "#         for j in range(nLayers):\n",
    "#             u =[]\n",
    "#             p =[]\n",
    "#             for k in range(nNodes):\n",
    "#                 t = np.dot(w[j]['weights'][k], prev)\n",
    "#                 u.append(t)\n",
    "#             for l in u:\n",
    "#                 p.append(tanh(l))\n",
    "#             p.append(1)\n",
    "#             prev = np.asarray(p)\n",
    "#         y = np.dot(w[nLayers][\"weights\"][0], prev)\n",
    "#         c += (d[i] - y)**2\n",
    "            \n",
    "#     return c/n\n",
    "\n",
    "\n",
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "    \n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000):\n",
    "#         self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         #self.ep = ep\n",
    "#         #self.train()\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         newdata = []\n",
    "#         for i in range(len(x)):\n",
    "#             newdata.append(np.append(x[i],1))     \n",
    "#         self.data = newdata\n",
    "#         self.weights = [{\"weights\":np.random.rand(self.nNodes, len(self.data[0]))}] #create the weights from the inputs to the first layer\n",
    "#         for i in range(self.nLayers-1):\n",
    "#             self.weights.append({\"weights\":np.random.rand(self.nNodes,self.nNodes+1)}) #create the random weights between internal layers\n",
    "            \n",
    "#         if self.nLayers > 0:\n",
    "            \n",
    "#             self.weights.append({\"weights\":np.random.rand(self.numOutputs,self.nNodes+1)}) #create weights from final layer to output node\n",
    "#         #return self.weights\n",
    "        \n",
    "        \n",
    "#     def train(self):\n",
    "#         print(self.weights)\n",
    "#         temp_eta = self.eta\n",
    "#         temp_weights = self.weights\n",
    "#         temp2 = mse(self.data, self.labels, self.weights, self.nLayers, self.nNodes)\n",
    "#         print(temp2)\n",
    "#         e = 0\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "#         cos = 100000000\n",
    "#         while e < self.maxIt:\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 print(self.data[i])\n",
    "#                 self.backprop(self.labels[i], self.data[i]) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "#                 print(self.weights)\n",
    "#                 print(f)\n",
    "\n",
    "\n",
    "\n",
    "#             cos = mse(self.data, self.labels, self.weights, self.nLayers,self.nNodes)\n",
    "\n",
    "# #             epoch.append(e)\n",
    "# #             obj.append(cos)\n",
    "# #             e += 1\n",
    "\n",
    "#             if cos > prev:\n",
    "#                 self.eta = 0.9*self.eta\n",
    "#                 if self.eta <= 0.00001:\n",
    "                    \n",
    "#                     self.eta = temp_eta  \n",
    "                    \n",
    "#                 obj =[]\n",
    "#                 epoch = []\n",
    "#                 e = 0\n",
    "#                 self.weights = temp_weights                \n",
    "#                 cos = 100000000\n",
    "\n",
    "#             elif cos <= prev:\n",
    "#                 epoch.append(e)\n",
    "#                 obj.append(cos)\n",
    "#                 e += 1\n",
    "\n",
    "#         #print(self.weights)\n",
    "#         return self.weights, obj, epoch   \n",
    "       \n",
    "\n",
    "#     def predict(self,x=[]):\n",
    "#         prev = x\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "        \n",
    "#         s =[]\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         #q = af(p)\n",
    "#         return p\n",
    "        \n",
    "#     def feedforward(self, data):\n",
    "#         r =[]\n",
    "#         prev = data\n",
    "#         r.append(prev)\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 #print(self.weights[j][\"weights\"][m])\n",
    "#                 s.append(np.dot(self.weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(af(k))\n",
    "#             l.append(1)\n",
    "#             prev = np.asarray(l)\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "            \n",
    "#         s =[]\n",
    "#         p = np.dot(self.weights[nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         q = af(p)\n",
    "#         t.append(s)        \n",
    "        \n",
    "#         return t,r\n",
    "\n",
    "#     def backprop(self, d, data):\n",
    "#         der = []\n",
    "#         t,r= self.feedforward(data)\n",
    "# #         print('\\n')\n",
    "# #         print(\"t = \" + str(t))\n",
    "# #         print('\\n')\n",
    "# #         print('r = ' + str(r))  \n",
    "#         q = self.predict(data)\n",
    "        \n",
    "#         for i in range(self.nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(self.nNodes):\n",
    "#                 a.append(af_derivative(t[i][m]))\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = d-q\n",
    "#         s =[]\n",
    "#         s.append(af_derivative(t[nLayers][0]))\n",
    "#         der.append(s)\n",
    "#         for i in reversed(range(len(self.weights))):\n",
    "#             layer = self.weights[i]\n",
    "#             errors = []\n",
    "#             if i != len(self.weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "                    \n",
    "#                     for k in range(len(self.weights[i + 1]['weights'])):\n",
    "#                         error += (self.weights[i + 1]['weights'][k][j] * self.weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#             else:\n",
    "#                 errors.append(diff)\n",
    "#             layer['s'] = []\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "\n",
    "#         for j in range(len(self.weights)):\n",
    "#             layer = self.weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(self.weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(self.weights[j]['weights'][k])):\n",
    "#                     s.append(((-(r[j][m])*self.weights[j]['s'][k])*2)/len(self.data))\n",
    "#                 layer['g'].append(s)\n",
    "\n",
    "#         return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Forward Propagation\n",
    "\n",
    "# def forw_prop(w, x, n, N):\n",
    "#     u = []\n",
    "#     p = []\n",
    "#     j = 0\n",
    "#     while j < 3*N and len(p)<24:\n",
    "#         u.append((w[j+1]*x)+w[j])\n",
    "#         p.append(tanh((w[j+1]*x)+w[j]))\n",
    "#         j += 2\n",
    "#     sum  = 0\n",
    "#     #print(p)\n",
    "#     for k in range(len(p)):\n",
    "#         sum += w[j+k] * p[k]\n",
    "#     y = sum + w[3*N]\n",
    "    \n",
    "#     return y,u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y,u = forw_prop(w0,x[1],n, N)\n",
    "# print(y)\n",
    "# print(d[0])\n",
    "# print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Back Propagation\n",
    "# def back_prop(d,x,w, n, N):\n",
    "#     g =[]\n",
    "#     y, u = forw_prop(w, x, n, N)\n",
    "#     diff = d - y\n",
    "#     i = 0\n",
    "#     j = 0\n",
    "#     while i < 3*N+1:\n",
    "#         if i % 2 == 0 and i < 48:\n",
    "#             m = -(der(u[j])*w[48+j])*diff\n",
    "#             #print(m)\n",
    "#             g.append(m)\n",
    "#         elif i % 2 != 0 and i < 48:\n",
    "#             g.append(-(der(u[j])*w[48+j])*diff)\n",
    "#             j += 1\n",
    "#         elif i >= 48 and i < 3*N + 1:\n",
    "#             g.append(-diff)\n",
    "#         else:\n",
    "#             g.append(-diff)\n",
    "#         i += 1\n",
    "    \n",
    "#     g = np.asarray(g)\n",
    "#     return (2*g)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = back_prop(d[2],x[2], w, n, N)\n",
    "# w = w - 0.45*g\n",
    "# y,u = forw_prop(w,x[2],n, N)\n",
    "# print(y)\n",
    "# print(d[0])\n",
    "# print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def alg(x, d, w, lr, n, N, iter):\n",
    "#     t = w\n",
    "#     obj =[]\n",
    "#     epoch = []\n",
    "#     e = 0\n",
    "#     epoch.append(e)\n",
    "#     obj.append(mse(x, d, w, n,N))\n",
    "#     cos = 100000000\n",
    "#     while e < iter:\n",
    "#         prev = cos\n",
    "#         i = 0\n",
    "#         while i < len(x):\n",
    "#             g = back_prop(d[i], x[i], w, n, N)\n",
    "#             w =  w - lr*g\n",
    "#             i += 1\n",
    "#         cos = mse(x, d, w, n,N)\n",
    "#         if cos > prev:\n",
    "#             lr = 0.9*lr\n",
    "#             obj =[]\n",
    "#             epoch = []\n",
    "#             e = 0\n",
    "#             epoch.append(e)\n",
    "#             obj.append(mse(x, d, t, n,N))\n",
    "#             cos = 100000000\n",
    "            \n",
    "#         elif cos <= prev:\n",
    "#             e += 1\n",
    "#             epoch.append(e)\n",
    "#             obj.append(mse(x, d, w, n,N))\n",
    "#             #print(g)\n",
    "#     return w, obj, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w0, cf, epoch= alg(x,d,w,1, n,N, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def forw_prop1(w, x, n, N):\n",
    "#     y =[]\n",
    "#     u = []\n",
    "#     for i in range(0,n):\n",
    "#         p = []\n",
    "#         j = 0\n",
    "#         while j < 3*N and len(p)<24:\n",
    "#             u.append((w[j+1]*x[i])+w[j])\n",
    "#             p.append(tanh((w[j+1]*x[i])+w[j]))\n",
    "#             j += 2\n",
    "#         sum  = 0\n",
    "#         #print(p)\n",
    "#         for i in range(len(p)):\n",
    "#             sum += w[j+i] * p[i]\n",
    "#         y.append(sum + w[3*N])\n",
    "\n",
    "#     y = np.asarray(y)\n",
    "#     return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit \n",
    "\n",
    "# y = forw_prop1(w0,x,n,N)\n",
    "# #print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #np.random.seed(100)\n",
    "# class NeuralNetwork:\n",
    "\n",
    "#     #Do not change this function header\n",
    "#     def __init__(self,x=[],y=[],numLayers=2,numNodes=2, numOutputs = 1, eta=0.001,maxIter=10000):\n",
    "#         self.data = x\n",
    "#         self.labels = y\n",
    "#         self.nLayers = numLayers\n",
    "#         self.nNodes = numNodes\n",
    "#         self.numOutputs = numOutputs\n",
    "#         self.eta = eta\n",
    "#         self.maxIt = maxIter\n",
    "#         #self.g = len(self.data[0])*numLayers + numLayers*numNodes + numNodes*numOutputs\n",
    "#         self.weights = [{\"weights\":[[np.random.random(), np.random.random()] for i in range(len(x[0])) for i in range(numNodes)]}]\n",
    "#         for i in range(self.nLayers-1):\n",
    "#             self.weights.append({\"weights\":[[np.random.random(), np.random.random()] for i in range(numNodes) for i in range(numNodes)]}) \n",
    "            \n",
    "#         if self.nLayers > 0:\n",
    "            \n",
    "#             self.weights.append({\"weights\":[[np.random.random() for i in range(numNodes+numOutputs)] for i in range(numOutputs)]}) \n",
    "#         self.outputs = np.zeros(y.shape)\n",
    "    \n",
    "\n",
    "#     def mse(x, d, w, n,N):\n",
    "#         c = 0\n",
    "#         u = []\n",
    "#         for i in range(0,n):\n",
    "#             p = []\n",
    "#             j = 0\n",
    "#             while j < 3*N and len(p)<24:\n",
    "#                 u.append((w[j+1]*x[i])+w[j])\n",
    "#                 p.append(tanh((w[j+1]*x[i])+w[j]))\n",
    "#                 j += 2\n",
    "#             sum  = 0\n",
    "#             #print(p)\n",
    "#             for k in range(len(p)):\n",
    "#                 sum += w[j+k] * p[k]\n",
    "#             y = sum + w[3*N]\n",
    "#             c += (d[i] - y)**2\n",
    "            \n",
    "#         return c/n\n",
    "\n",
    "        \n",
    "        \n",
    "#     def train(self):\n",
    "#         print(self.nNodes)\n",
    "#         print(self.weights)\n",
    "#         t = self.weights\n",
    "#         print(f)\n",
    "#         obj =[]\n",
    "#         epoch = []\n",
    "#         e = 0\n",
    "#         epoch.append(e)\n",
    "#         obj.append((self.data, self.labels, self.weights, len(self.data),self.nNodes))\n",
    "#         cos = 100000000\n",
    "        \n",
    "#         while e < self.maxIt:\n",
    "#             #print(\"-----------------------------------------------------------------------------------------------------------------------\")\n",
    "#             #print(\"Epoch \" + str(e))\n",
    "#             #print(\"The weights are \" + str(self.weights))\n",
    "#             prev = cos\n",
    "#             for i in range(len(self.data)):\n",
    "#                 #print(self.data[i])\n",
    "#                 #print(self.labels[i])\n",
    "#                 self.backprop(self.labels[i], self.data[i], self.weights, self.nLayers, self.nNodes) \n",
    "#                 for m in range(len(self.weights)):\n",
    "#                     for j in range(len(self.weights[m]['weights'])):\n",
    "#                         for k in range(len(self.weights[m]['weights'][j])):\n",
    "#                             self.weights[m]['weights'][j][k] -= self.eta *self.weights[m]['g'][j][k]\n",
    "#                 #print('\\n')\n",
    "#                 #print(self.weights)\n",
    "#                 #print(f)\n",
    "\n",
    "        \n",
    "#         cos = mse(self.data, self.labels, self.weights, len(self.data),self.nNodes)\n",
    "#         if cos > prev:\n",
    "#             lr = 0.9*lr\n",
    "#             obj =[]\n",
    "#             epoch = []\n",
    "#             e = 0\n",
    "#             epoch.append(e)\n",
    "#             obj.append((self.data, self.labels, t, len(self.data),self.nNodes))\n",
    "#             cos = 100000000\n",
    "            \n",
    "#         elif cos <= prev:\n",
    "#             e += 1\n",
    "#             epoch.append(e)\n",
    "#             obj.append(cos)\n",
    "#             #print(g)\n",
    "#         return self.weights, obj, epoch\n",
    "\n",
    "\n",
    "#     def predict(self,x=[]):\n",
    "#         #print('\\n')\n",
    "#         #print(\"Predict Function\")\n",
    "#         prev = x\n",
    "#         for j in range(self.nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(self.nNodes):\n",
    "#                 s.append(np.matmul(self.weights[j][\"weights\"][m], prev))\n",
    "#             for k in s:\n",
    "#                 l.append(tanh(k))\n",
    "#             prev = np.asarray(l)\n",
    "#         s =[]\n",
    "# #         for n in range(self.numOutputs):\n",
    "\n",
    "#         p = np.matmul(self.weights[self.nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "# #         q = []\n",
    "# #         for i in range(len(s)):\n",
    "#         q = tanh(p)\n",
    "#         return q\n",
    "\n",
    "#     def feedforward(self, data, weights, nLayers, nNodes):\n",
    "#         #This function is likely to be very helpful, but is not necessary\n",
    "#         #print('\\n')\n",
    "#         #print(\"Feedforward Function\")\n",
    "#         r =[]\n",
    "#         prev = data\n",
    "#         r.append(prev)\n",
    "\n",
    "#         t =[]\n",
    "\n",
    "#         for j in range(nLayers):\n",
    "#             l = []\n",
    "#             s = []\n",
    "#             for m in range(nNodes):\n",
    "#                 #print(weights[j][\"weights\"][m])\n",
    "#                 #print(prev)\n",
    "#                 s.append(np.dot(weights[j][\"weights\"][m], prev))\n",
    "            \n",
    "#             for k in s:\n",
    "#                 l.append(tanh(k))\n",
    "#             prev = np.asarray(l)\n",
    "#             #print(\"l \" + str(l))\n",
    "#             #print(\"Prev = \" + str(prev))\n",
    "#             t.append(s)\n",
    "#             r.append(l)\n",
    "        \n",
    "#         s =[]\n",
    "# #         for n in range(self.numOutputs):\n",
    "            \n",
    "# #             #print(weights[j+1][\"weights\"][k])\n",
    "#         p = np.dot(weights[nLayers][\"weights\"][0], prev)\n",
    "#         s.append(p)\n",
    "#         #p = sigmoid(p)\n",
    "#         t.append(s)\n",
    "#         #print(\"P = \"  + str(p))\n",
    "#         #print(\"t = \" + str(t))\n",
    "        \n",
    "        \n",
    "#         return t,r\n",
    "\n",
    "#     def backprop(self, d, data, weights, nLayers, nNodes):\n",
    "#         #This function is likely to be very helpful, but is not necessary\n",
    "#         #print('\\n')\n",
    "#         #print(\"BackProp\")\n",
    "#         der = []\n",
    "#         t,r = self.feedforward(data, weights, nLayers, nNodes)\n",
    "#         #print(t)\n",
    "#         #print(r)\n",
    "        \n",
    "#         q = self.predict(data)\n",
    "#         #print(q)\n",
    "#         #print(f)\n",
    "#         #r.append(q)\n",
    "#         #print(\"r = \" + str(r))\n",
    "#         #print(\"Q \" + str(q))\n",
    "#         for i in range(nLayers):\n",
    "#             a =[]\n",
    "#             for m in range(nNodes):\n",
    "#                 a.append(tanh_derivative(t[i][m]))\n",
    "#                 #print(a)\n",
    "#             der.append(a)\n",
    "        \n",
    "#         diff = []\n",
    "#         s =[]\n",
    "#         #for i in range(self.numOutputs):\n",
    "#         s.append(tanh_derivative(t[nLayers][0]))\n",
    "#         diff.append(d - q)\n",
    "#         der.append(s)\n",
    "#         #print('diff' +str(diff))\n",
    "#         #print('der' + str(der))\n",
    "#         #print(\"der \" + str(der))\n",
    "#         #print(\"diff = \" + str(diff))\n",
    "#         for i in reversed(range(len(weights))):\n",
    "#             #print(i)\n",
    "#             layer = weights[i]\n",
    "#             #print(\"Layer \" + str(layer))\n",
    "#             errors = []\n",
    "#             if i != len(weights)-1:\n",
    "#                 for j in range(len(layer['weights'])):\n",
    "#                     error = 0\n",
    "#                     #print('\\n')\n",
    "#                     #print('\\n')\n",
    "#                     #print(j)\n",
    "#                     #print(weights[i + 1]['weights'])\n",
    "#                     #print('C')\n",
    "                    \n",
    "#                     for k in range(len(weights[i + 1]['weights'])):\n",
    "#                         #print(\"k \" + str(k))\n",
    "#                         #print('D')\n",
    "#                         #print(weights[i + 1]['weights'][k][j])\n",
    "#                         #print(weights[i + 1]['s'][k])\n",
    "#                         error = (weights[i + 1]['weights'][k][j] * weights[i + 1]['s'][k])\n",
    "#                     errors.append(error)\n",
    "#                 #print('\\n')\n",
    "#                 #print('E')\n",
    "#                 #print(errors)\n",
    "#             else:\n",
    "#                 errors.append(diff[0])\n",
    "#                 #print(errors)\n",
    "#             layer['s'] = []\n",
    "#             #print(len(layer['weights']))\n",
    "#             #print(i)\n",
    "#             for j in range(len(layer['weights'])):\n",
    "#                 #print('\\n')\n",
    "#                 #print(\"der[i][j] \" + str(der[i][j]))\n",
    "#                 #print(\"errors \" + str(errors))\n",
    "#                 #print(errors[j]*der[i][j])\n",
    "#                 layer['s'].append(errors[j]*der[i][j])\n",
    "#             #print(\"For layer \" + str(i) + \" the weights are \" + str(self.weights))\n",
    "            \n",
    "#         #print(self.weights)       \n",
    "#         for j in range(len(self.weights)):\n",
    "#             layer = self.weights[j]\n",
    "#             layer['g'] = []\n",
    "#             for k in range(len(self.weights[j]['weights'])):\n",
    "#                 s =[]\n",
    "#                 for m in range(len(self.weights[j]['weights'][k])):\n",
    "#                     s.append(-(r[j][m])*self.weights[j]['s'][k])\n",
    "#                 layer['g'].append(s)\n",
    "        \n",
    "        \n",
    "                    \n",
    "                \n",
    "            \n",
    "#         #print('\\n')\n",
    "#         #print(self.weights)\n",
    "#         #g = np.asarray(g)   \n",
    "#         #print('\\n')\n",
    "#         return 0.0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def error(x, d, w, n,N):\n",
    "#     count = 0\n",
    "#     u = []\n",
    "#     for i in range(0,n):\n",
    "#         p = []\n",
    "#         j = 0\n",
    "#         while j < 3*N and len(p)<24:\n",
    "#             u.append((w[j+1]*x[i])+w[j])\n",
    "#             p.append(tanh((w[j+1]*x[i])+w[j]))\n",
    "#             j += 2\n",
    "#         sum  = 0\n",
    "#         #print(p)\n",
    "#         for k in range(len(p)):\n",
    "#             sum += w[j+k] * p[k]\n",
    "#         if d[i] != (sum + w[3*N]):\n",
    "#             count += 1\n",
    "            \n",
    "#     return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.5\n",
    "# e = 290\n",
    "# epoch = 0\n",
    "# errors = []\n",
    "# errors.append(error(x, d, w, n, N))\n",
    "# cos = 100000000\n",
    "# while errors[epoch] > e:\n",
    "#     prev = cos\n",
    "#     for i in range(len(x)):\n",
    "#         w =  w - lr*back_prop(d[i], x[i], w, n, N)\n",
    "#     errors.append(error(x, d, w, n, N))\n",
    "#     epoch += 1\n",
    "#     cos = cost(x, d, w, n,N)\n",
    "#     if cos > prev:\n",
    "#         lr = 0.9*lr\n",
    "#         #print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Forward Propagation\n",
    "\n",
    "# def forw_prop(w, x, n, N):\n",
    "#     y =[]\n",
    "#     u = []\n",
    "#     for i in range(0,n):\n",
    "#         p = []\n",
    "#         j = 0\n",
    "#         while j < 3*N and len(p)<24:\n",
    "#             u.append((w[j+1]*x[i])+w[j])\n",
    "#             p.append(tanh((w[j+1]*x[i])+w[j]))\n",
    "#             j += 2\n",
    "#         sum  = 0\n",
    "#         #print(p)\n",
    "#         for i in range(len(p)):\n",
    "#             sum += w[j+i] * p[i]\n",
    "#         y.append(sum + w[3*N])\n",
    "\n",
    "#     y = np.asarray(y)\n",
    "#     return y,u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Back Propagation\n",
    "# def back_prop(d,x,w, n, N):\n",
    "#     g =[]\n",
    "#     y, u = forw_prop(w, x, n, N)\n",
    "#     diff = d - y\n",
    "#     i = 0\n",
    "#     j = 0\n",
    "#     while i < 3*N+2:\n",
    "#         if i % 2 == 0 and i < 48:\n",
    "#             g.append(-(der(u[j])*w[48+j])*diff[j])\n",
    "#             i += 1\n",
    "#         elif i % 2 != 0 and i < 48:\n",
    "#             g.append(-(der(u[j])*w[48+j])*diff[j])\n",
    "#             i += 1\n",
    "#             j += 1\n",
    "#         elif i >= 48 and i < 3*N + 1:\n",
    "#             g.append(-diff[j])\n",
    "#             i += 1\n",
    "#         else:\n",
    "#             g.append(-diff[j])\n",
    "#             i += 1\n",
    "#     return g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
